Andrew Ng Y Combinator talk

June 17, 2025

youtube.com/watch?v=RNJCfif1dPY&vl=en-US

transcript: https://singjupost.com/andrew-ng-building-faster-with-ai-transcript/

---------


ANDREW NG: It’s really great to see all of you. What I want to do today, since this is Build a Startup School, is share with you some lessons I’ve learned about building startups at AI Funds. AI Funds is a venture studio, and we build an average of about one startup per month. And because we co-found the startups, we’re in there writing code, helping the customers design our features, determining pricing. And so we’ve done a lot of reps of not just watching others build startups, but actually being in the weeds, building startups with entrepreneurs.


What I want to do today is share with you some of the lessons I’ve learned building startups, especially around this changing AI technology and what it enables. And it’ll be focused on the theme of speed. It turns out that for those of you that want to build a startup, I think a strong predictor for startups’ odds of success is execution speed. I have a lot of respect for the entrepreneurs and executives that can just do things really quickly. And new AI technology is enabling startups to go much faster. So what I hope to do is share with you some of those best practices, which are frankly changing every two to three months still, to let you get that speed that hopefully lets you have a higher odds of success.


The AI Stack and Opportunities
Before diving to speed, a lot of people ask me, “Hey, Andrew, where are the opportunities for startups?” This is what I think of as an AI stack, where at the lowest level are the semiconductor companies, then the clouds or hyperscalers built on top of that.

A lot of the AI foundation model companies built on top of that. And even though a lot of PR excitement and hype has been on these technology layers, it turns out that almost by definition, the biggest opportunities have to be at the application layer, because we actually need the applications to generate even more revenue so that they can afford to pay the foundation, cloud, and semiconductor technology layers.
For whatever reason, media and social media tends not to talk about the application layer as much. But for those of you thinking of building startups, almost by definition, the biggest opportunities have to be there. Although, of course, the opportunities are all layers of the stack.

The Rise of Agentic AI
One of the things that’s changed a lot over the last year, and in terms of AI tech trends, if you ask me what’s the most important tech trend in AI, I would say it is the rise of agentic AI. About a year and a half ago, when I started to go around and give talks to try to convince people that AI agents might be a thing, I did not realize that around last summer, a bunch of marketers would get a hold of this term and use it as a sticker and slap it on everything in sight, which made it almost lose some of its meaning. But I want to share with you from a technical perspective why I think agentic AI is exciting and important and also opens up a lot more startup opportunities.

It turns out that the way a lot of us use LLMs is to prompt it, to have it generate an output. And the way we have an LLM output something is as if you’re going to a human or in this case an AI and asking it to please type out an essay for you by writing from the first word to the last word all in one go without ever using backspace. And humans, we don’t do our best writing, being forced to type in this linear order. And it turns out neither does AI. But despite the difficulty of being forced to write in this linear way, our LLMs do surprisingly well.

With agentic workflows, we can go to the AI system and ask it to please first write an essay online, then do some web research if it needs to, and fetch some web pages to put in the LLM context, then write the first draft, then read the first draft and critique it and revise it and so on. And so we end up with this iterative workflow where your model does some thinking, does some research, does some revision, goes back to do more thinking. And by going around this loop many times, it is slower, but it delivers a much better work product.

For a lot of projects that AI Fund has worked on, everything from pulling out complex compliance documents to medical diagnosis, to reasoning about complex legal documents, we found that these agentic workflows are really a huge difference between working versus not working. But a lot of the work that needs to be done, a lot of valuable businesses to be built still, will be taking workflows, existing or new workflows, and figure out how to implement them into these types of agentic workflows.

So just to update the picture for the AI stack, what has emerged over the last year is a new agentic orchestration layer that helps application builders orchestrate or coordinate a lot of calls to the technology layers underneath. And the good news is the orchestration layer has made it even easier to build applications. But I think the basic conclusion, the application layer has to be the most valuable layer of the stack still holds true.

Best Practices for Startup Speed
With a bias of focus on the application layer, let me now dive into some of the best practices I’ve learned for how startups can move faster. It turns out that at AI Fund, we only focus on working on concrete ideas. To me, a concrete idea, a concrete product idea, is one that specifies in enough detail that an engineer can go and build it.

For example, if you say, “Let’s use AI to optimize healthcare assets,” that’s actually not a concrete idea. It’s too vague. If you tell me to write software to use AI to optimize healthcare assets, different engineers would do totally different things. And because it’s not concrete, you can’t build it quickly and you don’t have speed.

In contrast, if you had a concrete idea, like “Let’s write software to let hospitals, let patients, let MRI machines fly online to optimize usage.” I don’t know if this is a good or a bad concrete idea. It’s actually business already doing this. But it is concrete, and that means engineers can build it quickly. If it’s a good idea, you find out it’s a good idea; if it’s not a good idea, you will find out. But having concrete ideas buys you speed.

Or if someone were to say, “Let’s use AI for email personal productivity.” Too many interpretations of that. That’s not concrete. But if someone says, “Can you build an app? Gmail integrated automation, let’s use the right problem source, right, filter and tag emails.” That is concrete. I could go build that this afternoon. So concreteness buys you speed.

The deceptive thing for a lot of entrepreneurs is the vague ideas tend to get a lot of kudos. If you go and tell your friends, “We should use AI to optimize the use of healthcare assets,” everyone will say that’s a great idea. But it’s actually not a great idea, at least in the sense of being something you can build. It turns out when you’re vague, you’re almost always right. But when you’re concrete, you may be right or wrong. Either way is fine. We can discover that much more fast, which is what’s important for a startup.

In terms of executing on concrete ideas, I find that in AI Fund, I ask my team to focus on concrete ideas because a concrete idea gives clear direction and the team can run really fast to build it and either validate it, prove it out, or falsify it and conclude it doesn’t work. Either way is fine. So let’s go and do that quickly.

It turns out that finding good concrete ideas usually requires someone, could be you, could be a subject matter expert, thinking about a problem for a long time. For example, actually before starting Coursera, I spent years thinking about online education, talking to users, holding my own intuitions about what would make a good ed tech platform. And then after that long process, I think YSP sometimes calls it wondering the idea maze. But after thinking about it for a long time, you find that the guts of people that thought about this for a long time can be very good about rapidly making decisions. As in, after you’ve thought about this, talked to customers for a long time, if you ask this expert, should I build this feature or that feature?

Their gut, which is an instantaneous decision, can be actually a surprisingly good proxy. It can be a surprisingly good mechanism for making decisions. And I know I work on AI. You might think I’ll say, oh, we need data. And of course, I love data. But it turns out getting data for a lot of startups is a slow mechanism for making decisions. And a subject matter expert with good guts is often a much better mechanism for making a speedy decision.

One other thing, for many successful startups, at any moment in time, you’re pursuing one very clear hypothesis that you’re building out and trying to sell, trying to validate, or falsify. And a startup doesn’t have resources to hedge and try 10 things at the same time. So pick one, go for it. And if data tells you to lose faith in that idea, that’s actually totally fine. Just pivot on the dime to pursue a totally different concrete idea.

So that’s what often feels like at AI fund. We’re pursuing one thing doggedly with determination until the world tells us we were wrong, then change and pursue a totally different thing with equal determination and equal doggedness.

One other pattern I’ve seen, if every piece of new data causes you to pivot, it probably means you’re starting off from too weak a base of knowledge. If every time you talk to a customer, you totally change your mind, probably means you don’t know enough about that sector yet to have a really high-quality concrete idea. And finding someone who’s thought about a subject for longer may get you on the better path.

Building Faster with AI Coding Assistance
In order to go faster, the other thing I often think about is the built feedback loop, which is rapidly changing when it comes to how we build with AI coding assistance. So when you’re building a lot of applications, one of the biggest risks is customer acceptance. A lot of startups struggle not because we can’t build whatever we want to build, but because we build something and it turns out nobody cares.

For a lot of the way I build startups, especially applications, less so deep tech, less so technology startups, but definitely application startups, is we often build software so there’s an engineering task and then we will get feedback from users and there’s a product management task and then we’ll go back, then based on the user feedback, we’ll tweak our views on what to build, go back to write more software and we go around this loop many, many times, iterate to what product market fits.

It turns out that with AI coding assistance, which Andrei talked about as well, rapid engineering is becoming possible in a way that just was not possible. It’s becoming much more feasible. So the speed of engineering is going up rapidly and the cost of engineering is also going down rapidly. This changes the mechanisms by which we drive startups around this loop.

Prototypes vs. Production Software
When I think about the software that I do, I maybe put it into two major buckets. Sometimes I’ll build quick and dirty prototypes to test an idea. So you build a new customer service chatbot, let’s build an AI to process legal documents, whatever. Build a quick and dirty prototype to see if we think it works. The other type of software where I do is maintain production software, maintain legacy software, but these massive production-ready code bases.

Depending on which analyst’s report you trust, it’s been hard to find very rigorous data on this. When writing production quality code, maybe we’re 30 to 50% faster with AI assistance. Hard to find a rigorous number. But in terms of building quick and dirty prototypes, we’re not 50% faster. I think we’re easily 10 times faster, maybe much more than 10 times faster.

ALSO READ:  TRANSCRIPT: Dark Side of AI - How Hackers use AI & Deepfakes: Mark T. Hofmann
There are a few reasons for this. When you’re building stand-alone prototypes, there’s less integration with legacy software infrastructure and legacy data needed. Also, the requirements for reliability, even scalability, even security are much lower.

I know I’m not supposed to tell people to write insecure code. Feels like the wrong thing to say. But I routinely go to my teams and they go ahead and write insecure code because if this software is only going to run on your laptop and you don’t plan to maliciously hack your own laptop, it’s fine to have insecure code. But of course, after it seems to be working, please do make it secure before you ship it to someone else. Leaking PII, leaking sensitive data, that is very damaging. So before you ship it, make it secure and scalable. But if you’re just testing it, it’s fine.

I find increasingly startups will systematically pursue innovations by building 20 prototypes to see what works. Because I know that there’s some ads in AI, a lot of proof of concepts they’ll make into production. But I think by driving the cost of a proof of concept low enough, it’s actually fine if lots of proof of concepts don’t see the light of day.

The mantra, “move fast and break things,” got a bad rep because, you know, it broke things. And some teams took away from this that you should not move fast, but I think that’s a mistake. I tend to tell my teams to move fast and be responsible. And I think there are actually ways to move really quickly while still being responsible.

Evolution of AI Coding Assistants
In terms of the AI assistance coding landscape, I think, was it three, four years ago, Code Autocomplete, right, popularized by GitHub Copilot. And then there was the cursor windserve generation of AI-enabled IDEs. We’re doing great, use windserve and cursor quite a lot. And then starting, I don’t know, six, seven months ago, there started to be this new generation of highly agentic coding assistants, including actually using O3 a lot for coding. Cloud Code is fantastic. Since Cloud 4 release, it’s become, and I’ll speak again in three months if I use something different, but the tool’s evolving really rapidly.

I think Cloud Code Codex is a new generation of highly agentic coding assistants that is making developer productivity keep on growing. And the interesting thing is, if you’re even half a generation or one generation behind, it actually makes a big difference compared to if you’re on top of the latest tools. And I find my team’s taking really different approaches to software engineering now compared to even three or six months ago.

The Changing Value of Code
One surprising thing is, we’re used to thinking of code as this really valuable artifact because it’s so hard to create. But because the cost of software engineering is going down, code is much less of a valuable artifact as it used to. So I’m on teams where we’ve completely rebuilt the code base three times in the last month, right? Because it’s not that hard anymore to just completely rebuild the code base, pick a new data schema, it’s fine. Because the cost of doing that has plummeted.

Some of you may have heard of Jeff Bezos’ terminology of a two-way door versus a one-way door. A two-way door is a decision that you can make. If you change your mind, come back out, you know, reverse it relatively cheaply. Whereas a one-way door is you make a decision and you change your mind, it’s very costly, very difficult to reverse.

So choosing the software architecture of your tech stack used to be a one-way door. Once you’ve built on top of a certain tech stack, you know, set a database schema, really hard to change it. So that used to be a one-way door. I don’t want to say it’s totally a two-way door, but I find that my team will more often build on a certain tech stack. A week later, change your mind, let’s throw the code base away and redo it from scratch on a new tech stack.

I don’t want to overhype it. We don’t do that all the time. There are still costs to redoing that. I find my team is often rethinking what is a one-way door and what’s now a two-way door because the cost of software engineering is so much lower now.

Maybe going a little bit beyond software engineering, I feel like it’s actually a good time to empower everyone to build AI. Over the last year, a bunch of people have advised others not to learn to code on the browser. AI will automate it. I think we’ll look back on this as some of the worst career advice ever given because as better tools make software engineering easier, more people should do it, not fewer.

Many decades ago, the world moved from punch cards to keyboard and terminal that made coding easier. When we moved from assembly to high-level languages like COBOL, there were actually people arguing back then that now we have COBOL, we don’t need programmers anymore. People actually wrote papers to that effect. But, of course, that was wrong, and programming languages made it easier to code and more people learned to code.

Text-to-speech, IDEs, AI coding assistants, and as coding becomes easier, more people should learn to code. I have a controversial opinion, which is I think it’s time for everyone in every job role to learn to code. In fact, on my team, my CFO, my head of talent, my recruiters, my front desk person, all of them know how to code. I actually see all of them performing better at all of their job functions because they can code. I think I’m probably a little bit ahead of the curve. Most businesses are not there yet, but in the future, I think we’ll empower everyone to code. A lot of people can be more productive.

I want to share with you one lesson I learned as well on why we should have people learn to do this, which is when I was teaching Generative AI to Everyone on Coursera, we needed to generate background art like this using Mid-Journey. One of my team members knew art history, and so he could prompt Mid-Journey with the genre, the palette, the artistic inspiration, had a very good control over the images he generated, so we ended up using all of Tommy’s generated images.

In contrast, I don’t know art history, and so when I prompt image generation, I could write, “please make pretty pictures of robots for me.” I could never have the control that my collaborator could, and so I couldn’t generate as good images as he could.

I think with computers, one of the most important skills of the future is the ability to tell a computer exactly what you want so they will do it for you. It will be people that have that deeper understanding of computers that will be able to command a computer to get the outcome you want, and learning to code, not that you need to write the code yourself, see an AI to code for you, seems like it would be the best way to do that for a long time.

Shifting Dynamics in Product Management
With software engineering becoming much faster, the other interesting dynamic I’m seeing is that the product management work, getting user feedback, deciding what features to build, that is increasingly the bottleneck. And so I’m seeing very interesting dynamics in multiple teams. Over the last year, a lot more of my teams have started to complain that they’re bottlenecks on product engineering and design, because the engineers have gotten so much faster.

Some interesting trends I’m seeing, three, four, five years ago, Silicon Valley used to have these slightly suspicious rules of thumb, but nonetheless rules of thumb, will have 1 PM to 4 engineers, or 1 PM to 7 engineers. It was just like PM product manager to engineering ratio, right? I think we’re getting past those typicals of 1 PM to 6, 7 engineers. And with engineers becoming much faster, I don’t see product management work, designing what to build, becoming faster at the same speed as engineers. I’m seeing this ratio shift.

So literally yesterday, one of my teams came to me, and for the first time, when we’re planning to hit a conference project, this team proposed to me not to have 1 PM to 4 engineers, but to have 1 PM to 0.5 engineers. So the team actually proposed to me, I still don’t know if this is a good idea. It was the first time in my life that I saw engineers propose to me, having twice as many PMs as engineers. It was a very interesting dynamic. I still don’t know if this proposal I heard yesterday is a good idea, but I think it’s a sign of where the world is going. And I find that PMs that can code, or engineers with some product instincts, often end up doing better.

Tactics for Getting Product Feedback
The other thing that I found important for startup leaders is, because engineering is becoming so fast, if you have good tactics, so getting rapid feedback to shape your perspective on what to build faster, it helps you get faster as well. So I’m going to go through a portfolio of tactics for getting product feedback to keep shaping what you will decide to build. And we’re going to go through a list of the faster, maybe less accurate, the slower, more accurate tactics.

So the fastest tactics for getting feedback is, look at the product yourself, and just go by your gut. And if you’re a subject matter expert, this is actually surprisingly good, if you know what you’re doing.

A little bit slower is, go ask three friends or teammates to get feedback, to play their product and get feedback.

A little bit slower is, ask three to ten strangers for feedback. It turns out, when I built products, one of the most important skills I think I learned was how to sit in the coffee shop, how to sit in a, when I travel, I often sit in the hotel lobby. It turns out, learn to spot places with high foot traffic, and very respectfully, you know, grab strangers and ask them for feedback on whatever I’m building. This used to be easier when I was less known, when people recognized you, it was a little bit more awkward.

But I found that, I’ve actually sat with teams in the hotel lobby, very high foot traffic, and, you know, very respectfully ask strangers, “hey, we’re building this thing, do you mind taking a look?” Oh, and I actually learned in the coffee shop that a lot of people working, a lot of people don’t want to be working, so we give them an excuse to be distracted, and they’re very happy to do that too. But I’ve actually kind of made tons of product decisions in the hotel lobby or the coffee shop with collaborators, just like that.

Send prototypes to a hundred testers, if you have access to larger groups of users, send prototypes to more users, and these are, these get to be slow and slower tactics.

And I know Silicon Valley, you know, we like to talk about A-B testing. Of course, I do a ton of A-B testing, but contrary to what many people think, A-B testing is now one of the slowest tactics in my menu, because it’s just slow to ship it. It depends on how many users you have, right?

And then the other thing is, as you use anything but the first tactic, some teams will look at the data, they make a decision, but the missing piece is, when I A-B test something, I don’t just use the result of A-B test to pick product A or product B. My team will often sit down and look carefully at the data to hone our instincts, to speed up, to improve the rate at which we’re able to use the first tactic, to make high-quality decisions.

We often sit down and think, “gee, I thought, you know, this product name will work better than that product name. Clearly, my mental model that I use is wrong.” So we sit down and think, to update our mental model, using all of that data to improve the quality of our guts on how to make product decisions faster. That turns out to be really important.

Understanding AI Accelerates Progress
All right, so we talked about concrete ideas, speed up engineering, speed up product feedback. This is one last thing I want to touch on, which is, I’ve seen that understanding AI actually makes you go faster, and here’s why. As an AI person, maybe I’m biased to be pro-AI, but I want to share with you why.

ALSO READ:  A Memoir of My Life with Steve Jobs by Chrisann Brennan (Transcript)
So it turns out that when it comes to mature technology, like mobile, you know, many people have had smartphones for a long time. We kind of know what a mobile app can do, right? So many people, including non-technical people, have good glimpses of what a mobile app can do.

If you look at mature job roles, like sales marketing, HR, legal, they’re all really important, all really difficult, but, you know, there are enough marketers that have done marketing for long enough, and the marketing tactics haven’t changed that much in the last year. So there are a lot of people that are really good at marketing, and it’s really important, really hard, but that knowledge is relatively diffused because, you know, the knowledge of how to do HR, it hasn’t changed dramatically, you know, in the last six months. But AI is emerging technology,

And so the knowledge of how to do AI really well is not widespread, and so teams that actually get it, that understand AI, do have an advantage over teams that don’t. Whereas if you need an HR problem solved, you can find someone that knows how to do it well, probably, but if you have an AI problem, knowing how to actually do that could put you ahead of other companies.

Things like, what accuracy can you get for a customer service chatbot? Should you prompt or fine-tune using a RAG workflow? How do you get a voice out to those low latencies? There are a lot of these decisions that, if you make the right technical decision, you can solve the problem in a couple of days. If they make the wrong technical decision, you could chase a blind alley for three months.

One thing I’ve been surprised by: it turns out if you have two possible architecture decisions, it’s one bit of information. It feels like, if you don’t know the right answer, at most, you’re twice as slow, right? It’s one bit. Try both. It feels like one bit of information can, at most, buy you a two-week speed-up. And I think, in some theoretical sense, that is true, but what I see in practice, if you flip the wrong bit, you’re not twice as slow, you spend like ten times longer chasing a blind alley, which is why I think having the right technical judgment really makes startups go so much faster.

Building with AI Building Blocks
The other reason why I find sitting on top of AI really helpful for startups is, over the last two years, we have just had a ton of wonderful Gen-AI tools, or Gen-AI building blocks. A partial list includes prompting, agentic workflows, evals, guardrails, RAG, voice stack, async programming, lots of ETL, embeddings, fine-tuning, GraphDB, how to compute used, MCP, using models. Just a long and wonderful list of building blocks that you can quickly combine to build software that no one on the planet could have built even a year ago. And this creates a lot of new opportunities for startups to build new things.

When I learned about these building blocks, this is actually a picture that I had in mind. If you own one building block, like you have a basic white building block, you can build some cool stuff. Maybe you know how to prompt, so you have one building block. You build some amazing stuff. But if you get a second building block, like you also know how to build chatbots, so you have a white Lego brick and a black Lego brick, you can build something more interesting. And if you acquire a blue building brick as well, you can build something even more interesting. Get a few red building bricks, maybe a little yellow one, more interesting. Get more building bricks, get more building bricks, and very rapidly, the number of things you can combine them into grows kind of combinatorially or grows exponentially.

So knowing all these wonderful building blocks lets you combine them in a much richer combination. One thing that DeepLearning.AI does, I actually take a lot of DeepLearning.AI short courses myself, because I work with all the leading AI companies in the world and try to hand out building blocks. But when I look at the DeepLearning.AI course catalog, this is actually what I see. And whenever I take new courses and learn these building blocks, I feel like I’m getting new things that can combine to form kind of combinatorially or exponentially more software applications that were not possible just one or two years ago.

Conclusion
So just to wrap up, this is my last slide. Anyone want to take questions if you all have any? I find that there are many things that matter for a startup, not just speed. But when I look at the startups that AI Fund is building, I find that the management team’s ability to execute at speed is highly correlated with its odds of success.

And some things we’ve learned to get you speed is, work on concrete ideas. It’s got to be good concrete ideas. I find that as an executive, I’m judged on the speed and quality of my decisions. Both do matter, but speed absolutely matters. Rapid entry with AI coding assistance makes you go much faster, but that shifts the bottleneck to getting user feedback and the product decisions. And so having a portfolio of tactics to go get rapid feedback. And if you haven’t learned to go to a coffee shop and talk to strangers, it’s not easy, but just be respectful of people. That’s actually a very valuable skill for entrepreneurs to have, I think. And I think also staying on top of AI technology buys you speed.

All right. With that, let me thank you very much.