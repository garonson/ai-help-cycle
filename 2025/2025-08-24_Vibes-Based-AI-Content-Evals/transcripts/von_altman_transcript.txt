Transcript of Sam Altman appearance on Theo Von's "This Past Weekend w/ Theo Von #599"

Video link: https://www.youtube.com/watch?v=aYn8VKW6vXA&t=831s

Released July 23, 2025

Transcription by Glen Aronson w/ Gemini 2.5 Pro 8/10/25

Obvious ad breaks removed, some known transcription errors remain but seem minimal based on quick spot check.


---------------------------------------------------------


[00:00] [Theo Von] Today's guest is uh, well, dude's a straight up tech lord. Let's be honest. He's uh, he's one of the leaders, the world leaders in the development of AI. Um, he started Open AI, which is known for uh having Chat GPT. Uh, we had a fascinating chat about the pros and cons, um, the fears and hopes, everything I could learn about uh about artificial intelligence and where we're headed. TBD, baby. Today's guest is Mr. Sam Altman and I'm very thankful for his time.

[00:50] [Sam Altman] You know, we had a residential architect do this office. We wanted it to feel like someone's like really comfortable like country house or something like that.

[00:57] [Theo Von] Yeah.

[00:57] [Sam Altman] Not like the big corporate like sci-fi castle.

[01:00] [Theo Von] Yeah, that's what I was I was like a little bit like, oh, is it going to be, you know, will there be a draw bridge? Will we be uploaded into a suite? Like what will happen to us? You know.

[01:09] [Sam Altman] Yeah, we don't want that. We went for like residential.

[01:11] [Theo Von] Yeah, I was like, how do we even get through the firewall? How many like hit points will we need to get through? You know, it got very dungeons and dragons uh in some of my like um, imagination sometimes.

[01:21] [Sam Altman] Yeah, we want people to feel like super comfortable and tried to get pretty far in that direction.

[01:25] [Theo Von] It feels like it. Your staff's very sweet, nice people. Um you have, thanks for hanging out, man.

[01:31] [Sam Altman] Absolutely, thanks for coming.

[01:32] [Theo Von] Really appreciate it. Uh yeah, I haven't seen you since I fell out of my chair.

[01:35] [Sam Altman] You fell out of your chair at the inauguration. That was really like quite a way to meet you.

[01:39] [Theo Von] Yeah, I felt so embarrassed.

[01:40] [Sam Altman] And you were one of the faces that I looked up and saw and I was like, God.

[01:43] [Theo Von] And that was my first moment like AI built us a better chair to be honest with you.

[01:48] [Sam Altman] And you did nothing, right? You were just sitting there and it just collapsed.

[01:51] [Theo Von] Nothing.

[01:51] [Sam Altman] I remember that.

[01:52] [Theo Von] And it was just so embarrassing. I was like, oh, of all people me and here I am in this place.

[01:58] [Sam Altman] I think it was perfect because everybody's got to have some story and people are like, oh, what was the inauguration like? Everybody's got to have some story to tell.

[02:03] [Theo Von] Yeah. And that was an incredible story for us all to tell.

[02:05] [Theo Von] It's a good point. I do remember looking at people for help though. And oddly your eyes, I I was like, oh my god, he could help. You did look like a beacon of help in the distance.

[02:15] [Sam Altman] I tried to help.

[02:15] [Theo Von] Um you have a baby, have a new.

[02:18] [Sam Altman] Yeah. Child.

[02:20] [Sam Altman] It is. There have been like a lot of experiences in life where everyone tells you something's going to be great. And then it's like, okay, the people are right, the consensus is right. It's like even better than I thought it was going to be. But this has been the strongest example of that ever. Like I knew it was going to be great and it's like way, way better. It's impossible to describe. There's nothing I can say that's not like very cliche. And it's totally amazing.

[02:44] [Theo Von] What is like one of your and it's a you have a young boy? Yeah.

[02:47] [Theo Von] And what's something like that you think is like neat or like what's one thing that kind of like is bringing you joy with it?

[02:54] [Sam Altman] Watching the speed with which he like learns new things or gains new capabilities is just unbelievable. It's like every day it's like, oh man, he just couldn't do that before. And now he's like grabbing stuff and passing it between his hands and uh getting to like watch it day to day is just an amazing rate of change. And then I don't like I again, I realized it's like you know, I realize that like everything about babies are very finely tuned over a long period of evolution to make us like love them and be fascinated by them and it's like a neuro chemical hack. But I love it. It's great. It's so strong, it's so intense.

[03:32] [Theo Von] So it's really like almost like a coffee for your heart or something kind of?

[03:35] [Sam Altman] I don't even know how to find. I've tried to like come up with an analogy to tell because now I'm like telling everybody, you got to have a lot of kids it's really important. Yeah, yeah, yeah. And I've been looking for an analogy of what to explain. And then I always just say like, I don't know how to explain this. It's just it is the best thing I've ever done by far. I feel like a completely changed person. And I was I was like thinking the other day, like there used to be all these at this point, all I do is work and hang out with my family. Like I don't I don't really get to do a lot of hobbies anymore. It's a busy time at work. I don't get to hang out with my friends that much. Uh and and I don't, you know, there were like all these things where people tell you like, oh, you got a baby coming. You got to go, you know, take that spontaneous international trip because you're not going to be doing that again for a long time. And I was like, oh, that is kind of sad. In practice, you don't do it that often. I at least didn't do it that often. and I don't miss it at all. I like remember that that used to be a possibility. Now I can see that's not going to be a possibility for a long time and I'm thrilled with the trade.

[04:32] [Theo Von] You're moved on.

[04:32] [Sam Altman] I'm so happy.

[04:34] [Theo Von] How old is your child?

[04:35] [Sam Altman] Four months.

[04:36] [Theo Von] Oh, that's a funny like at five or six months, they start to get like fun and you can like they're still like they can't go anywhere, you know?

[04:42] [Sam Altman] Yeah. He's totally like turned on now.

[04:43] [Theo Von] But they're like intrigued and stuff.

[04:45] [Theo Von] They start to like smile or process more. I don't know how you guys say it.

[04:49] [Sam Altman] Yeah, really aware, understands things. It's super cool.

[04:52] [Theo Von] I have a thought sometimes that this will be one of the last like maybe 40 years that we conceive children in the body. Did you have any thoughts about that?

[05:03] [Sam Altman] I've definitely heard a lot of people say that. Um I haven't thought about it hard myself, but yeah, I guess that does make sense.

[05:13] [Theo Von] Like, God, you were in your mom's butt. It's crazy, you know.

[05:18] [Sam Altman] It is crazy.

[05:18] [Theo Von] You pervert or whatever. Like I think in the future people will be, it'll be kind of done like in a in a vat or something.

[05:24] [Sam Altman] Yes.

[05:24] [Theo Von] In like a nice vat, you can go see it on the weekends or whatever.

[05:27] [Sam Altman] It doesn't that just feel like off to you? Like I can totally intellectually like understand that that maybe the better way to do it.

[05:35] [Theo Von] Oh yeah, it feels way off to me. I was trying to I thought you would like it.

[05:38] [Sam Altman] You know.

[05:39] [Theo Von] Like I thought I thought like or I thought you that would be like a thought. I guess I, like that for me, that's one of like my futuristic thoughts, you know.

[05:47] [Sam Altman] Like I can totally accept that that will be what everybody does and that it's, you know, easier and we can like make it healthier for the child and the mother. You know, the mother doesn't take the health risk, but but man, I mean, so intellectually I can say that and then emotionally it feels like, ah, something is off with that.

[06:06] [Theo Von] Oh yeah. Yeah, because then the family like on the weekends the parents would come and like tinker on the glass or whatever, or the dad would put like a um, you know, like a go Falcon sticker on the thing or you know what I'm saying? People would like decorate it all up or write little messages on there.

[06:22] [Sam Altman] You know, I think there's another like another take I have on all this is that there in this world that we're heading to of like crazy sci-fi technology becoming reality, the the sort of like the deeply human things will become the most precious sacred valued things. And then we'll really care about like the human experience more than ever. Maybe it won't go that way. I don't know. Yeah.

[06:43] [Theo Von] Do you? No, and that's some of the stuff we want to talk about and thanks thanks so much man for sitting down. Um do you think your child will go to college? Do you think like what do you kind of think that looks like?

[06:53] [Sam Altman] Probably not. Um if I had to guess, like I think I mean, I only went to half of college.

[06:59] [Theo Von] You dropped did you drop out?

[07:00] [Sam Altman] Dropped out.

[07:00] [Theo Von] Yeah. Dude, you guys all, I freaking dropped out and I didn't get shit. You dropped out, Wang dropped out, Zuckerberg dropped out. Probably a lot of other people.

[07:09] [Sam Altman] And you?

[07:10] [Theo Von] Yeah, and okay, yeah, okay. Well, hey, we're both here. So, it worked out fine.

[07:14] [Sam Altman] Yeah, you're right.

[07:16] [Theo Von] You're right. Never mind, I'm sorry, I'm being self-defeating.

[07:19] [Theo Von] Yeah, what does that look like when you think about that? Like yeah, with AI with so much new information coming online, right? And so much like data being collected and like um, information being car pooled and and which is a term.

[07:33] [Sam Altman] So you and I never grew up in a world that didn't have computers. Right. Like and and our parents were like, oh, this there weren't computers and then there were and it was this big crazy adjustment and it took them a long time to figure it out. But to us, like computers just always existed. They were just, I mean, maybe they were kind of new but they were always around. And and then like, you know, a kid that is like there was there's this video on YouTube I saw like maybe 12 years ago or something like that that has really stuck with me. It was like a little baby and a dentist waiting room or something picking up one of those old glossy magazines and going like this.

[08:07] [Theo Von] Oh, I remember that.

[08:09] [Sam Altman] And to that kid, it was just like a broken iPad because that kid had just like grown up in a world where like there were touch screens everywhere. And my kid will never grow up, will never ever be smarter than an AI. That will never happen. You know, kid born a few years ago, they had a brief period of time. My kid never will be smarter. But also they'll never they'll never know a world where like products and services aren't way smarter than them. And and super capable. They can just do whatever you need. And in that world, I think education's going to feel very different. I already think college is like maybe not working great for most people. But yeah, I think fast forward 18 years, it's going to look like a very, very different thing.

[08:52] [Theo Von] Yeah. Do you think that here's that video right here of this kid?

[08:54] [Sam Altman] Yeah, yeah, yeah. All right, I was wrong about the dentist. It was or maybe there's a few of these.

[08:59] [Theo Von] He's like somebody charge this magazine, he's yelling.

[09:02] [Theo Von] How would you recommend to a parent right now to prepare their children for like an AI future? Kind of like are there certain curtails that you would start to put in now? Are there certain like um you know adjustments where you like get them in a certain training or have them start to watch certain models of things online? Like what is that?

[09:18] [Sam Altman] I I actually think the kids will be fine. I'm worried about the parents.

[09:21] [Theo Von] Ah.

[09:22] [Sam Altman] If you look at the history of the world here when there's new technology, like people that grow up with it, they're always fluent. They always figure out what to do. They always learn the new kind of jobs. But if you're like a 50-year-old and you have to like kind of learn to do things in a very different way, that doesn't always work. Yeah. So I think the kids are going to be fine. I mean, I do have worried like I do have worries about kids and technology. Like I think this scrolling, the kind of like you know, short video feed dopamine hit feels like it's probably messing with kids' brain development in a super deep way.

[09:54] [Theo Von] Yeah, for sure.

[09:55] [Sam Altman] So it's not that I have no worries. I have like extremely deep worries about what technology is doing to kids. But in terms of kids' ability to like be prepared for the future and use the new technology, they seem really good at that.

[10:04] [Theo Von] Always through history.

[10:05] [Theo Von] It's a good point actually. Yeah, it's like if you just grow up with it, it's just like having it's just totally normal. It's like having knee caps or whatever. You're just kind of used to it.

[10:13] [Sam Altman] You can't imagine the world where it doesn't exist. You just that's right.

[10:16] [Theo Von] Yeah. Yeah.

[10:18] [Theo Von] It's a good point.

[10:19] [Sam Altman] I remember when I was uh in school and like junior high and Google first came out and all the teachers like freaked out. And they were like, this is the end of education, you know, if you why do you have to memorize history facts in history class if you could just look them up instantly on the internet? You don't even have to learn to go to the library. And the answer is like, yeah, maybe memorization is less important. But with these new tools, you can think better, come up with new ideas, do new stuff. I'm sure the same thing happened with the calculator before. Yeah. And you know, now this is like this is just a new tool that exists in the tool chain.

[10:50] [Theo Von] And what about like, say if there is somebody that's like learning history right now, like they just started their second year of college, they're they're taking history. Is that still a viable space of work uh as AI moves forward, do you think honestly?

[11:33] [Sam Altman] I I assume there will be some version of it that is, uh, I I it's very hard to predict exactly how something evolves. Um I or predict exactly what the jobs of the future are going to be. Like the you know, not that long ago, it would have been very hard to predict either of our jobs. If you go back 100 years, the idea of like this CEO of an AI company or a podcast, like you know, probably would have been things that didn't seem to be the most obvious evolutions of the things people were doing at the time.

[12:11] [Theo Von] Yeah, you just seemed almost probably crazy even in trying to explain those to someone.

[12:15] [Sam Altman] You would. And now, in fact, two of the I I heard that the job that young people most want is some version of your job. The job that young people most want is to be a, you know, podcast, influencer, uh YouTuber, they want a YouTube channel. Whatever it is, they they like six, seven year olds, they don't know how to describe it, but that's what they want. And a lot of people also want my job. They want to do like a startup or they want to work on AI and these just didn't exist. So the rate with which the new things come along is is fast. And also trying to predict what they are. I don't know. The thing I say all the time is no one knows what happens next. It's like we're going to figure this out. It's this weird emergent thing. Does the current job of a historian exist in the same way? I would bet not quite. But another thing I believe is that humans are obsessed with other people. We are so deeply wired to care about other people, to care about stories, and history, our own history, is extremely interesting to us. So I would say somehow or other, we're still going to care about that. There's going to be some kind of job doing that.

[13:13] [Theo Von] Mm. Man, that's cool. I guess I I I when I take that avenue of thought, like, okay, there will still be this historian or something like that, it'll be some evolution of that, right? That does seem kind of cool to me because there's a level of creativity in there. There's a level of like faith and spontaneity in there that I think is kind of exciting. So yeah, I guess I hadn't really thought about that. Sometimes I get stuck in this Dooms Day thing, like I just see like, you know, the history book closes and they're like, we have enough, we have all the history over here.

[13:44] [Sam Altman] You know, people used to say like, oh, there's no need for more music. We've been made perfect music. Like why does anyone need anyone to create anymore? And that's obviously ridiculous. Yeah. Or they would say there's that famous patent office quote, everything that humans ever possibly need has been invented. There's nothing left to do.

[13:58] [Theo Von] I have heard that. But here we are.

[13:59] [Sam Altman] Here we are. And and like I mean, they used to say this. They used to this like the Industrial Revolution. People were like, oh, you know, we just figured out how to automate like man's lot in life. There's nothing left to do. We're going to have these machines do all the work. It makes sense probably. And you watch these machines doing all this stuff that only people used to physically do. And everybody panicked and said there's going to be no more jobs. And we figured out new stuff to want. Now, here's an interesting thing. If you could go back to that industrial revolution time and people before that were, you know, really on the grind, working super hard, trying to like kind of have enough food to survive. Go back to those people. Look at our jobs today. Would those people say we have real jobs? Or would they say you have unbelievable abundance, unbelievable wealth, so much food to eat, incredible luxury and you guys are just like playing a game to entertain yourselves. Is that a real job or not? And they would probably say where they sit, what you guys do is not a real job. You guys are you know, you're too rich, you're wasting your time. You're trying to like

[16:20] [Theo Von] Yeah, you guys are a couple of dang zest lords out there freaking playing Uno in the park or whatever. They would they would not, I don't think my grandfather would be like, you have a job. He would still be like, you need to get a job.

[16:28] [Sam Altman] Yeah, totally.

[16:30] [Theo Von] And when we look forward another 100 years at what people are doing, they'll probably think they're working very hard. It'll feel very satisfying, very intense to them. They'll really like they'll feel engaged. They'll be making other people happy. They'll be creating value for each other. But if we could look forward that 100 years at those guys, do you think we would say they're working? Or like, man, you have like AI doing everything for you. You're just trying to entertain yourselves.

[16:49] [Theo Von] Yeah, I'd be like, oh, you guys have it so easy. Right.

[16:52] [Sam Altman] But I think that's beautiful. I think it's great that those people in the past think we have it so easy. I think it's great that we think those people in the future have it so easy. Like that is the beautiful story of us all contributing to human progress and everybody's lives getting better and better.

[17:06] [Theo Von] Say we're able to get to that space, right? Like the move like the movement that happens with AI and with just technology, which will advance quicker, I think which is one thing that AI feels like to me is a fast forward button on technology and on possibility because things can be information can be quantified so quick and a lot of like uh more menial tasks, even though they're not really menial in people's lives. Um but menial hypothetically can be done quicker to get a lot of the framework for things done fast. But how will people survive, like how do we adjust our structure of like financially of like if some people own the companies that have the AI and then a lot of people are just using the AI and the agents created by AI to do things for them. How will society like societal members still be able to financially survive? Will there still be money? What is that? Does that make any sense that question?

[18:00] [Sam Altman] It makes total sense. Um I don't know and neither is anybody else, but I'll tell you my current best guess. Okay. Or I'll say two guesses. One, I think it is possible that we put you know, GPT 7 or whatever in everybody's chat GPT. Everybody gets it for free. and everybody has access to just this like crazy thing such that everybody can be more productive, make way more money. It doesn't actually matter that you don't like own the cluster itself, but everybody gets to use it and it turns out even getting to use it is enough that people are like getting richer faster and more distributed than ever before. That could happen. I think that really is possible. There's another version of this where the most important things that are happening are these systems are discovering, you know, new cures for diseases, new kinds of energy, new ways to make spaceships, whatever. And most of that value is accruing to the like cluster owners. us just so that I'm not dodging the question here. And then I think society will very quickly say, okay, we got to have some new some new economic model where we share that and distribute that to people. I I used to be really excited about things like UBI. I still am kind of excited.

[19:11] [Theo Von] Universal basic income. Yeah, you hear that term a lot.

[19:12] [Theo Von] Universal basic income. Yeah, I heard you and Rogan talking about that too a while back.

[19:16] [Sam Altman] I still am kind of excited about that, but I think people really need agency. Like they really need to feel like they have a voice in governing the future and deciding where things go. And I think if you just like say, okay, AI is going to do everything and then everybody gets a you know, dividend from that. It's not going to feel good and and I don't think it actually would be good for people. So I think we need to find a way where we're not just like, if we're in this world, where we're not just distributing money or wealth, like I actually I don't just want like a check every month. What I would want is like a ownership share and whatever the AI creates so that I feel like I'm participating in this thing that's going to compound and get more valuable over time. So I sort of like universal basic wealth better than universal basic income and I don't like basic either. I want like universal extreme wealth for everybody. Um but but even then, like I think what people really want is the agency to kind of co-create the future together. And in a world where it's like the AI is mostly coming up with the new scientific inventions, at least we've got to still have humans like invent the new culture and have that be a very distributed thing.

[20:29] [Theo Von] Ah, okay. I guess I I I I see what you're saying. is that like an American thing, do you think? Like since they were invented here or do you think I'm just wondering what does that look like, you know?

[20:41] [Sam Altman] The economic model of it all or the whole thing?

[20:42] [Theo Von] Yeah, or like, or is there a dividend of the company that's then is divided up between the masses sort of?

[20:50] [Sam Altman] I mean, a crazy idea, but in the spirit of crazy ideas, is that if the world, there's like eight roughly 8 billion people in the world. If the world can generate like eight quintillion tokens per year, if that's the world's, actually, let's say the world can generate 20 trillion quintillion, 20 quintillion tokens per year.

[21:09] [Theo Von] Tokens of like a each word generated by an AI.

[21:12] [Theo Von] Just making up a huge number here.

[21:13] [Theo Von] We'll say, okay, 12 of those go to, you know, the normal capitalistic system, but eight of those, eight quintillion tokens are going to get divided up equally among eight billion people. So everybody gets one trillion tokens. And that's your kind of universal basic wealth globally. And people can sell those tokens. Like if I don't need mine, I can sell them to you. We could pull ours together for some like new art project we want to do. But but instead of just like getting a check, you're getting everybody on earth is getting like a slice of the world's AI capacity. And then we're letting the like massively distributed human ingenuity and creativity and economic engine do its thing. I mean, that's like a crazy idea, maybe it's a bad one. But that's the kind of thing that I think sounds like someone should think about it more.

[21:58] [Theo Von] one of the big fears is like purpose, right? Like human purpose. like work gives us purpose. And also I think the idea that we are the ones advancing society humanity gives us purpose. Like we are the like yeah, like we have some control over our own destiny gives us a sense of purpose. And it feels like that we would lose a sense of purpose or that purpose would be adjusted like if AI is to really, you know, continue to advance so quickly. It feels like our sense of purpose would start to really disappear.

[22:36] [Theo Von] Do you have you had thoughts about that?

[22:37] [Sam Altman] Yeah, I worry about this a lot. It's so I think people have worried about this with every big technological revolution. But I agree that this time it feels different.

[22:45] [Theo Von] Like, okay, yeah, because if, say you had an axe and some guy come up with a saw, you're like, you're fine.

[22:49] [Sam Altman] Or even if they come up with like a robot that cuts the tree down. It still feels fine. But like creativity and intelligence, I think cuts so deeply at the core of whatever we are and how we how we value ourselves. Um one example we can look at this right now, I think one area where AI is having a big impact is on how people write software for a living. And AI is really good at that and it's really changed what it means to be a software developer. I haven't heard any of those software developers say that they even though their job is different that they don't have meaning. They still enjoy it. They're operating at a higher level. Um and I'm hopeful, at least for a long time, you know, 100 years from now, who knows, but I'm hopeful that that's what it'll feel like with AI is even if we're asking it to solve huge problems for us. Even if we ask it to say like, you know, go discover a cure for cancer. There will still be a lot of things to do in that process that feel valuable to a person. You're still asking it the questions, you're still like helping guide it, you're still framing it or whatever it is, you're still talking to the world about it. And and I also like, you know, a real problem with this earlier, but it can get much worse is just what this is going to mean for user's mental health. There are a lot of people that talk to Chat GPT all day long. They are these sort of new AI companions that people talk to like they would a girlfriend or a boyfriend. Um, and we were talking earlier about how it's probably not been good for kids to like grow up like on the dopamine hit of scrolling.

[27:26] [Theo Von] You know, Tik Tok videos or whatever.

[27:27] [Theo Von] Yeah, for sure. Yeah.

[27:28] [Theo Von] Do you think that how do you keep like um, AI from having that same effect, like that negative effect that social media really has had.

[27:35] [Sam Altman] I'm I'm scared of that. I don't I don't have an answer yet. Uh, I don't think we know quite the ways in which it's going to have those negative impacts. Uh, but I feel for sure it's going to have some and we'll have to I hope we can learn to mitigate it quickly.

[27:49] [Theo Von] Um can AI's, can they pull up pornography and stuff like that too or no?

[27:53] [Sam Altman] Sure.

[27:54] [Theo Von] Oh my God. God, I didn't know that.

[27:58] [Sam Altman] Mm-hmm.

[28:00] [Theo Von] Ah. Well, hey, it's fine. No, it's fine. I just, yeah, I don't even need to know that. I'm going to have that stricken from my own record.

[commercial break]

[30:49] Theo Von: Um, what legal system does AI have to work by? Is there like a legal, like, or there, like we have laws like in the world, right? Like in the human world. Is in, does AI have to work by any like legal laws, you know?

[31:03] Sam Altman: Yeah, so I think we will certainly need a legal or a policy framework for AI. Um, one example that we've been thinking about a lot, this is like a, maybe not quite what you're asking, this is like a very human-centric version of that question. People talk about the most personal shit in their lives to ChatGPT. It's, you know, people use it, young people especially, like use it as a therapist, a life coach, uh, having these relationship problems, what should I do? And right now, if you talk to a therapist or a lawyer or a doctor about those problems, there's like legal privilege for it. You know, like it's, there's doctor-patient confidentiality, there's legal confidentiality, whatever. And we don't, we haven't figured that out yet for when you talk to ChatGPT. So if you go talk to ChatGPT about your most sensitive stuff and then there's like a lawsuit or whatever, like we could be required to produce that and I think that's very screwed up. I think we should have like the same concept of privacy for your conversations with AI that we do with a therapist or whatever. And no one had to think about that even a year ago. And now I think it's this huge issue of like, how are we going to treat the laws around this?

[32:10] Theo Von: Do you think there should be like kind of like a like a slowing things down before we move there kind of because yeah, it is kind of wild. It's one of the reasons I get scared sometimes to use certain AI stuff because, um, I don't know how much personal information I want to put in because I don't know who's gonna have it.

[32:25] Sam Altman: I think we need this point addressed with some urgency. Um, and, you know, the policymakers I've talked to about it like broadly agree. It's just it's new and we got to do it quickly. Do you talk to ChatGPT?

[32:36] Theo Von: I don't talk to it that much.

[32:38] Sam Altman: It's because of this?

[32:39] Theo Von: I think it is. It's because it's like

[32:40] Sam Altman: I I think it makes sense. I to not talk to ChatGPT because

[32:44] Sam Altman: No, no, no, to like really want the privacy clarity before you use it a lot.

[32:48] Theo Von: Yeah.

[32:48] Sam Altman: Like the legal clarity.

[32:49] Theo Von: Yeah, it's scary. And it's like, well how long does it take lawmakers to come up with that? And then it feels like it's moving so fast that it's like it doesn't even matter that that sometimes it's like it doesn't even really matter. It's like, are we even waiting for the laws to be put around this or or what's going on? Does it feel like it's moving too fast for you sometimes?

[33:07] Sam Altman: The last few months have felt very fast. It feels faster and faster, but the last few months have felt very fast.

[33:13] Theo Von: Yeah, I was watching this guy, um, Yoshua Bengio?

[33:17] Sam Altman: Yoshua Bengio.

[33:18] Theo Von: Yoshua Bengio. And he's kind of like, some people call him the father of AI. He may be self-proclaimed, I'm not really sure. Um, but he's certainly seem to be kind of like a lifeguard for AI. Like thinking about like, you know, how do we keep the pool safe? You know, how much water should be in it? You know, the chlorine, what, you know, how many lifeguards you need on duty, that type of thing, hypothetically. Um, and he said, and he was saying that some AIs, they have like deception techniques inside of them. Like, that there were AIs that would rather give you an answer that was possibly pleasing to the user than to give them the factual answer. Um, and then he was also saying that there were um, AIs that were developing some of their own languages to communicate with each other. which would be languages that we don't even know. Um, what is that? How do you guys curtail that when those types of things come up? What does that even kind of feel like to you guys or are these just problems that happen in new spaces and you figure it out as you go?

[34:21] Sam Altman: You know, there are these moments in the history of science where you have a group of scientists look at their creation and just say, you know, what what have we done? What have we done? Maybe it's great, maybe it's bad, but what have we done? Like maybe the most iconic example is thinking about the scientists working on the Manhattan Project in 1945 sitting there watching the Trinity test and just, you know, this thing that had, it was a completely new, not, not human-scale kind of power and everyone knew it was going to reshape the world. And I do think people working on AI have that feeling in a very deep way. You know, we just don't know, like, we think it's going to be great. There are clearly real risks. It kind of feels like you should be able to say something more than that, but in truth, I think all we know right now is that we have discovered, invented, whatever you want to call it, something extraordinary that is going to reshape the course of human history.

[35:20] Theo Von: Dear God, man. But if you don't know, we don't know.

[35:24] Sam Altman: Well, of course. I mean, I I think no one, no one can predict the future. Like human society is very complex. This is an amazing new technology. Maybe a less dramatic example than the atomic bomb is when they discovered the transistor a few years later.

[35:40] Theo Von: The transistor radio?

[35:41] Sam Altman: The little transistor part that, you know, made computers and radios and everything else. But we discovered this completely new thing that enabled the whole computer revolution and is in this microphone and those computers and our iPhones and like the world would be so different if people had not discovered that and then over the decades figured out how to make them smaller and more efficient. And now we don't even think about it because the transistors are just in everything. We have all this modern technology from that one scientific discovery. And I do think that's what AI is going to be like. We had this one crazy scientific discovery that led to these language models that we all use now and that is going to change the course of society in all kinds of ways and and of course we don't know what they all are.

[36:23] Theo Von: Damn. I was hoping you knew by the end of that sentence. Or I was hoping you would, you know. Like that's the worry.

[36:30] Theo Von: Cuz we don't know. You know, like that's I think the tough thing.

[36:34] Sam Altman: There's no time in human history at the beginning of a century where the people ever knew what the end of the century was going to be like.

[36:39] Theo Von: Yeah.

[36:40] Sam Altman: So maybe it's And I do think it goes faster and faster each century. It's certainly like, you know, in 1900 you couldn't predict what 2000 was going to be like. I think in 2000 you could even less predict what 2100 was going to look like. But that's kind of why it's exciting. And like that's kind of why people get to figure out and unfold the story as we go.

[36:59] Theo Von: It's kind of bizarre because there's there's a part of me that's like, this guy's out of his mind. This guy is a is a crazy is a wild wizard, you know, there's a couple different things. But then there's also this part of me that's like, this guy is this hopeful guy who's like involved in this crazy space and he kind of has this whimsical energy about the future, which is in a crazy way, a nice energy to have about the future generally is that something could happen or that things are possible. Um, so it's just, yeah, it's all kind of like

[37:32] Theo Von: it's definitely fascinating to me. Um, Sam, to kind of pivot a little bit. There's it feels like there's a race right now in AI. Right? Would you say that there's a race between companies and AI?

[37:45] Sam Altman: It certainly feels that way.

[37:47] Theo Von: Yeah. And it almost feels like you guys are the new Formula One drivers. Are you guys are like the new like uh it's like um Mario Andretti or you guys are the new like uh Bubba Watson, all the, you know, it's almost like these are the new race cars that everybody's kind of watching position themselves. Um, what is the race for? Because you hear about AI and then you hear about AGI. Uh and then you hear about superintelligence. What is what is this race that's going on? How real is it and what is the race for?

[38:21] Sam Altman: When I was a kid, the race was like the megahertz race and then it became the gigahertz race. Everybody wanted a computer with a faster processor.

[38:28] Theo Von: Oh yeah.

[38:28] Sam Altman: You know, Intel would come out with this one and then AMD would come out with this one and everybody like and it turned out that those gigahertz measurements eventually were not even that helpful. Like you could have one that had a lower number and it was in practice it was faster. And eventually I think it was Apple that realized they should just stop talking about the clock speed of their computersand you probably don't even know what the processor speed of your iPhone is today.

[38:52] Theo Von: Yeah, it's true. It yeah, that was a big thing and it kind of disappeared.

[38:55] Sam Altman: And I think the same thing has been happening in AI where everybody was racing on these benchmarks. I score this on this benchmark and this on that one. And now people are realizing that like, okay, the benchmarks are kind of saturated. We went through the equivalent of our megahertz race with our benchmark race. And now people kind of don't care about that as much. And now it's like who's using the model, who's getting the value out of it, all things like that. Um but I do think people still feel like we're heading towards some milestone. What the milestone is, they disagree on, but maybe it's a system that's capable of doing its own AI research and its own self-improvement. Um, maybe it's a system that is like smarter than all of humans put together. But they feel like there is some finish line to cross. I actually don't quite feel like this, but I think a lot of people in the industry, there's some finish line that we're going to cross. Maybe it's this like self-improvement moment, maybe you call that super intelligence. Um

[40:04] Theo Von: What are you racing towards you feel like?

[40:07] Sam Altman: It's a great question. Um, I don't have like a finish line in mind. There's nothing I could say that I I don't think I can articulate anything where I would say like, this is mission complete. But if I if I had to give like a self-referential answer there, you know, the moment where we would rather give our research cluster, like our, you know, GPUs that we run all of our AI experiments on, the moment where we would rather give that to an AI researcher rather than our brilliant team of human researchers. That does at least seem like some kind of very different new era.

[40:45] Theo Von: Yeah. And at that point, who's even we? I feel like it's just you kind of like wheeling the stuff across the hall in a, you know, like who's gonna, you know what I'm saying? It starts to get this idea like if we keep, if every, if things were to keep leaving the people and go to the computer

[41:04] Sam Altman: again, I assume that what will happen, like with every other kind of technology is we'll realize like we, there's this one thing that the tool's way better than us at, now we got to go solve some other problems. So let's put our brain power there.

[41:16] Theo Von: Yeah. I spot I don't think it'll ever feel like we all just get to like push a button and go on vacation.

[41:21] Theo Von: got it.

[41:23] Sam Altman: Um, like we will I think as as capabilities go up because as we get better tools, the expectation goes way up too. And so we've got to like yes, we get much better tools, but we have to do way more to remain competitive.

[41:39] Theo Von: I think there's this hopeful idea, this safe if you come up with all these

[41:42] Sam Altman: or maybe not, like maybe the AI is just better than us at absolutely everything and we just sit there and be like, all right, that was cool.

[41:47] Theo Von: Yeah, cuz at a certain point if something has all the information, right? If something has all the information it can think and and ponder and pontificate and serve multi options of answers. Aren't we then working for that thing? Like that's what I start to wonder. Like if it's the smartest thing in the room

[42:06] Sam Altman: GPT 5 is the smartest thing in the room. GPT 5 is smarter than us in almost every way. You know, and yet here we are. So there's like, there's something about the way the world works, there's something about just doesn't mean it's true forever. But there's something about what humans can do today that is so different, there's also something about what humans care about today that is so different than AI that I don't think the simplistic thing quite works. Now, again, by the time it's a million times smarter than us, who knows.

[42:35] Theo Von: Is part of you want to kind of get there? Like, how do we get where like I open the door and you and I say, excuse me, sir. And it's just my computer in there, you know? Like

[42:44] Sam Altman: You know, when when I was a kid, I I sort of thought about these technological revolutions that happened one at a time. There was the agricultural revolution a long time ago and that freed us up to do these other things. And then there was the age of enlightenment, there was the industrial revolution, there was the computer revolution and all these things happened and I thought of them as like these distinct things. And now I view it as just this one long compounding exponential where all of these things come together, each piece of technology is built continuously overlapping on the one that comes before and we're able to just do more and more. And so, in some sense, AI is this big special unique different thing. And in some other sense, it's just part of this long arc of human progress. We talked about the transistor earlier, but like that was way more important in some sense to AI happening than the work we do now. And all this stuff has to like compound, compound, you got to build the internet, you got to get all this data, you got to do all these things. And I want that exponential to keep going. There'll be things way after AI. We'll invent all sorts of new things, we'll go colonize space, we'll go, you know, build neural interfaces, who knows what else we'll do. But I think at some point, AI fades into that arc of history. We build, we we don't even think about it. It's like transistors if you don't even think about today, it's just another layer in the scaffolding that humans collectively have built up bit by bit over time. And where you sitting our day, you get to open that door. You have this like computer that only has one interface. You just it says what do you want. You say whatever you want, it happens and you figure out amazing new things to build for the next generation and the next and the next. And we just keep going.

[44:29] Theo Von: I think the part that I think gets spooky is I can't build any, I can build some stuff, but I can't build like any technological stuff. So then I'm like, dang dude, well I'm not gonna what am I gonna build over there?

[44:43] Sam Altman: Okay, so right now I can write software, maybe you can't and I have a little advantage if I want to go build something technological thing. And very soon you can make any piece of software you want because you just ask an AI in English. You say, I got an idea for an app, make me this thing and the whole thing just happens. So that's a win for you. Maybe it's a little bit of a loss for me. I think it's kind of cool for the whole world.

[45:02] Theo Von: Yeah. But um like

[45:03] Sam Altman: This is this is going to be a technology that anybody can use. You can just like with natural language, you can say, this is what I want and it goes off and writes the code for you, debugs it for you, deploys it for you.

[45:15] Theo Von: And then you can say how do I use what I just created?

[45:17] Sam Altman: Yeah, but if you have a great idea AI will just make it happen for you. And this is a new thing. Like this is I think this will make technology the most accessible it ever has been.

[45:26] Theo Von: Got it. Okay, then that seems a little bit different. I think there's this idea in my head that I'm going to have to figure out all this coding, I'm going to figure out all of these different ways to do things to even have a possibility of of use of myself in the future.

[45:40] Sam Altman: No, I think this is uh without talking too much about the future and what we're going to launch. Like the fact that you will be able to have an entire piece of software created just by like explaining your idea is going to be incredible for humans getting great new stuff because right now, I think there's like a lot more good ideas than people who know how to make them.

[46:00] Theo Von: Mmm hmm.

[46:00] Sam Altman: And if AI can do that for us, we're really good at coming up with creative ideas.

[46:04] Theo Von: Yeah, I mean that's one of the things that people like to do.

[46:07] Theo Von: Um,

[46:09] Theo Von: Do you think right now if, if humans, regular, average humans, most humans could vote to keep AI going or to stop AI, what do you think they would vote?

[46:17] Sam Altman: That's a great question. Mmm. This is like totally kind of I don't have any data for this. I would bet most people who use ChatGPT which is a lot of people now, they would say like, keep it going. And most people who don't would say, it's scary, stop it. What do you think?

[46:32] Theo Von: Yeah, I feel like most people would say stop it I think or pause it, take the wheels off of it for a month, that kind of thing, siphon the gas out of the tank, you know, like that kind of thing, put sugar in it. I think there would like that kind of thing.

[46:47] Sam Altman: What are you most afraid of with it? Or is it just that we're not going to have purpose and we don't know how it's all going to go?

[46:52] Theo Von: Yeah, I mean there's some of the huge parts, but I think like, probably that. I think that in the end, I think there's a general feeling of like, well, if all the trucking jobs disappear, you know if those become automated and um and like yeah, if everything becomes a robo taxi, like you know, will that feel, you know, where will those people go for jobs? Will everybody just be dancing on TikTok trying to get people to tip them for trends and stuff? You know, like there's part of that. I had this dream years ago that it all ends with everybody's driving an Uber and literally holding each other at gunpoint to be each other's passengers, right? Like get in my car because that's how bad like somebody's like, I need the fair more than you do. You know, my whole family's in the backseat, you sit shotgun, we'll get you to where you're at. You know, like people are literally holding each other at gunpoint to subscribe to their OnlyFans and stuff, like it's just that dystopian or whatever. Um, so I guess part of that, but then there's a deeper part where it's like, yeah, what comes out of us if it feels like a lot of the regular stuff that gives us purpose that we know right now gives us purpose. Is there a new evolution of our purpose? Is there like a blooming inside of us? Is it this utopian place that you almost think of as like a heaven idea where you know, people's are fed and have enough, you know, can take, are provided for, can take care of themselves. I guess that's what that that's it or what, because purpose gives people work gives people so much of their purpose and so if we're to lose that, then what is it, what happens? And I know I kind of keep asking that over and over again. You don't really have the answers and that's it's okay, of course, how could you? We're not in the future.

[48:38] Sam Altman: I mean, I think people really do love to be useful to each other and people love to express their creativity as part of that. And as the long-term trend of society getting richer has continued, more people are able to do get closer to sort of expressing themselves in the best way that they can. May may maybe like as recently as 500 or 600 years ago, not very many people got to be artists. The world wasn't that rich. There were a limited number of patrons that could like pay you to create art, but there were more than zero and before that there were almost none. And then you got this beautiful Italian Renaissance and all of this amazing art uh because there was like excess capital in the world. And now a lot more people can be artists or a lot more people can start startups, which is another like for me that's my expression of creativity. Um or more people can create content. Yeah. Uh and this idea that people can find whatever way they can to express themselves, their talent, their vision, um for kind of collective love of other people. And a care for putting their brick in society's progress. I think that can go really far. Now what art in the future looks like now that AI can make art or help make art, I don't know, it'll probably be kind of different. What startups will look like in the future when people can kind of just say whatever they want to their AI and it can make the software for them right then, it'll probably be different. But I think it's such a bad bet to assume that either human creativity or human fulfillment from being useful to other people ends. I think we just, we stand on this exponential and like each year, each decade, our collective standard of living goes way up, the whole world gets way richer, we all get more, we all expect more. And even over like the course of, I was thinking recently, like food is so much better than it is when I was a kid. Like the world has just figured out how to make food better. Like we've, you know, know how to, we figured out organic vegetables or whatever it is. I don't know, it just tastes much better. And like, I think that's great. I don't want to go back to eating like the frozen carrots or whatever.

[51:00] Theo Von: Yeah. That's a good point. But then there's some, like I saw this thing the other day, it was like a kit, they had like one of those robo kitchens or whatever. You know when you order food from like something dash or whatever.

[51:10] Sam Altman: Mmmhmm.

[51:10] Theo Von: And then you and it's like Hank's Ribs and then it's like Marty's Pizza and then it's like Susan's Salami shop but they're all the same place, you know.

[51:23] Sam Altman: And when you get that from when you get that from Window Dash, Yeah. Uh you don't you don't like, you feel like something's missing, right? You're like, ah this is fake. I can tell. I get less enjoyment. You would rather get that food from like the dude who's been making it and perfecting it on the you know, that little pizza shop on the corner for the last 20 years. Correct. Because that's like part of like that dude is part of the experience, that authenticity is part of the experience. I don't think that goes away with the like fake robotic thing. Okay.

[51:51] Theo Von: Yeah, because I think I start to feel like we're in this universe where it's like, you're walking down the street or something and like a Waymo goes by and it's like, eat now. And you're like, but and you already ate, it's just got a bad reading or something. It's got a bad valve in it or something. You're yelling at it, there's nobody in there. And you're like, I already ate. It's like, sit down and eat now. And it just like fucking uses like a t-shirt cannon, it just like shoots a burrito at you or something. And then you're sitting there eating that, you know. And then the GLP car goes by, right?

[52:20] Sam Altman: And it says I can help you out.

[52:21] Theo Von: Yes, and it's like, obviously you've overeaten. You're like, I didn't even want to eat. That thing's messed up, right? You're yelling at a car that has no driver in it and then it shoots you with three GLP one darts in the neck and now your wife doesn't even recognize you when you get home or whatever, you know.

[52:36] Sam Altman: The fact that you find this so off-putting, I think is a sign for optimism.

[52:42] Theo Von: Yeah. That's actually a good point. It's kind of you're like wired. You're going to be resistant to that. That's not going to make you happy. That's not going to make other people happy. Now, maybe we get tricked. Like social media tricked us for a while. We got too addicted to feeds. Whatever. But we realized like actually this is not helping me be my best. You know, like doing the equivalent of getting the burrito cannon into my mouth on my phone at night, like that's not making me long-term happy and that's not helping me like really accomplish my true goals in life. And I think if AI does that, people will reject it. However, if if ChatGPT really helps you to figure out what your true goals in life are and then accomplish those. You know, it says, hey, you've said you want to be a better father or you know, you want to be in better shape or you, you know, want to like grow your business. Um you can if you want, we can change that goal and I can help you scroll Tik Tok all night or, you know, eat the burritos or whatever and I'll give you the GLP one shots and I'll make you as healthy as you can be. But like maybe instead I can try to help convince you you should go for a run tonight. And I think if AI feels like it is helping you try to accomplish your goals and be your best, that will feel very different than the last generation of technology.

[53:52] Theo Von: Yeah. And you know what and that's where I'm like, and that's where a kid growing up right now to them that would probably, some young people would be like that makes the most sense. I'm a little older generation, I'll be like that seems a little bit. But that's always how things are with generation and generation.

[54:04] Sam Altman: It's always how it goes.

[54:06] Theo Von: Yeah, you're right. And maybe this is just like a quicker evolution of things and for young people it's going to make so much sense and for older people, it's and you're just going to be like, get off my, you know, avatar lawn or something, you know.

[54:19] Sam Altman: But that's the way of societal progress. That's just how it goes.

[54:21] Theo Von: It's a good point.

[commercial break]

[55:48] Theo Von: there's there's definitely been a lot of talk about like tech and governance, right? And I know we've touched on it a little bit earlier. Um and there were people like lobbying in the uh in Trump had a big beautiful bill for like a 10-year ban on uh state legislation against AI. Um what do you think about that like letting it be this rogue space

[56:09] Sam Altman: There have to be some rules here. There has to be some like guidelines, there has to be some sort of regulation at some point. I think it'd be a mistake to let each state do this kind of crazy patchwork of stuff. I think like one countrywide approach would be much easier for us to be able to innovate and still like have some guard rails. But there have to be some guard rails.

[56:31] Theo Von: Do you have you met with governments and like government leaders to have discussions like that? Like are they meeting with you because they might they've

[56:38] Sam Altman: Yeah, yeah, they do meet with us. They haven't done anything big yet but they're talking about it.

[56:42] Theo Von: Do they meet with you to try to keep information out of, um, you guys' data?

[56:48] Sam Altman: You know, for all of the paranoia about that, I don't think we've ever had someone come say like, I don't want it to say this negative thing about this politician or this whatever. Uh, the the concerns are like, what is this going to do to our kids? Are they going to stop learning? There's a lot of concerns about that. Um, is this going to spread fake information? Is this going to influence elections? But we've never had the like, you can't say bad things about the president Trump or whatever.

[57:14] Theo Von: What about bias is a big thing. Like they they do want to know like, you know if it'll say bad things about one candidate, it'll say bad things about the other.

[57:20] Theo Von: Could you guys make it do one or the other? Like can you guys favor the back end or

[57:25] Sam Altman: We totally could. I mean, we don't, but we totally could.

[57:27] Theo Von: You could? Yeah.

[57:28] Theo Von: Wow.

[57:29] Sam Altman: Yeah. I think like

[57:30] Theo Von: I know you, how do you mean? Like do we give you guys lie detector tests? I'm like how do we know

[57:35] Sam Altman: Well, you can, like you test the system. Anyone can like test the AI and say if I say this, this to say this, if I say

[57:40] Theo Von: Oh, that's a good point.

[57:40] Sam Altman: But you you touch on a really big point here, which is like hundreds of millions of people talk to ChatGPT every day. And it probably has like a big impact on what they believe and so I think society's interest in making sure that we are, you know, a responsible neutral party should be huge. Now people do test a lot and I think that's good. But like we got to be held to a very high standard there.

[58:06] Theo Von: But how do we like just as regular people or how do like regular people just hold you guys to a high standard? Like is it their I guess it's politicians responsibility or I mean these guys are idiots. someone they're like 80-year-old dude giving thumbs up that one guy couldn't get the Wi-Fi on. Remember that guy? That guy couldn't get the Wi-Fi on. So I'm like how do we

[58:24] Sam Altman: I mean there's a huge amount of people that test our systems all the time looking for any errors, any bias, any anything.

[58:30] Theo Von: So I guess it's a good point is we can tell.

[58:31] Sam Altman: You can tell. You can tell.

[58:32] Theo Von: Right. People can test it on this end.

[58:35] Theo Von: Yeah.

[58:37] Theo Von: As as AI grows, like how big do data centers need to be? Is that a concern of you guys?

[58:44] Sam Altman: I went recently to one of our new data centers under construction in Abilene, Texas. It was about like a approximately a 1 gigawatt facility, huge. You know, it'll be the biggest data center ever built by the time it's done. And you stand in the middle of this and the scale of this project just hits you so big. That's like one little, that's like one little part of it.

[59:06] Theo Von: Dude, that's like eight Costcos.

[59:08] Sam Altman: There's like 5,000 people there doing construction on it and this thing is just standing up making progress every day. And you stand in the middle of this thing

[59:15] Theo Von: And what are you in a chariot or whatever? Like how do you even

[59:17] Sam Altman: you're in a you're in like in a little ATV. Oh, it's like a dirty kind of construction site. But the scale of this thing and then you kind of go in every room and you look at all the cables, the power, the cooling systems, rack after rack after rack of serve of server servers. It's humongous. There's like, there's standing up these like power plants right in the middle of it.

[59:38] Theo Von: Oh yeah.

[59:39] Sam Altman: It's crazy to see.

[59:40] Theo Von: it looks, it starts to make our planet look like, um, a software board, like a

[59:46] Sam Altman: it does. You know, when you see it from the air. I was really struck by that. I was like this looks like the motherboard of a computer.

[59:53] Theo Von: Yeah, it looks like the motherboard of a computer. You start to see like how the planet's in like a lot of these like uh sci-fi movies, a lot of them look have that same feel.

[02:00:00] Theo Von: R2-D2 look on the outside because they've been

[02:00:02] Sam Altman: Covered in data centers.

[02:00:03] Theo Von: Yeah. Which is kind of wild. Do you know where we're going and you're not telling us? Are you, do you know what's happening?

[02:00:08] Sam Altman: I don't.

[02:00:09] Theo Von: You promise, dude.

[02:00:09] Sam Altman: I don't know. I mean, I have all my guesses. Like I do guess that a lot of the world gets covered in data centers over time.

[02:00:15] Theo Von: You really?

[02:00:15] Sam Altman: But I don't know, cause maybe we put them in space.

[02:00:18] Theo Von: Mmm.

[02:00:18] Sam Altman: Like maybe we build a big Dyson sphere on the solar system and say, hey, actually it makes no sense to put these on Earth.

[02:00:23] Theo Von: Yeah.

[02:00:24] Sam Altman: I wish I had like more concrete answers for you, but like we're stumbling through this. We maybe, you know, have a little bit higher confidence than the average person or but there's so much we don't know yet.

[02:00:34] Theo Von: No, that's the craziest thing about you, Sam, and and I I think this is a compliment somehow, dear God. And it yeah, it is a compliment. You're like, it's like, you're like, come with me through the universe and you're like, people are like, what's it like? You're like, I don't know exactly but and then we're all go and it's like we're all going. It's like, um, I don't know. You're just somehow the most like, uh, you're this like, charming kind of terminator it feels like. And I hate to say terminator, that's a crazy term. But like, uh, but you're this like, you're like, I'm like, fuck, okay. I'm I'm curious. You somehow seem so optimistic about it. I'm it it adds to my curiosity.

[01:01:14] Sam Altman: When I was a kid, I assumed that there were always some adults in the room. Someone had a plan. Someone knew everything that was going to happen. Someone had it all figured out. And I sort of think why people like conspiracy theories is it's nice to think that someone's got a plan. It's nice to think someone that uh, you know, has it all figured out. And then I got a little bit older and I sort of started to suspect there are no adults in the room. No one, people have plans. I have plans. But no one has all the answers. No one knows where it's all going to go. Uh, and now that I am the adult in the room, I can say with certainty, no one knows where it's all going to go. Like, I'm the guy in the room and I have some guesses and I have some plans, uh, and we're working really hard. But like, you know, we try to always say what we think the possibilities are, what we think is most likely. Often we're right. Sometimes it's in the broader set and sometimes it goes in a totally different direction than anything we thought. And, you know, we keep trying to make progress, figure out more. We try to tell people, not just tell, we try to show people by like deploying these systems and say, hey, you can go use it. Don't just take our word for it, try it out, see what it can do. Yeah. Um, but like I can say with conviction that the world needs a lot more processing power. But if that looks like tiling data centers on Earth, which I think is what it looks like in the short term, in the long term also, or we do go build them in space. I don't know, it sounds cool to try to build them in space, but also really hard.

[01:02:41] Theo Von: Well what about like the environmental effects of those and stuff? Like there's been like, you know, there's been articles written and I don't know how much of it is real or not real, right? Because you who knows what to believe. But you'd have to think that you know, it takes water to cool them, right? It takes power to power them. you know, um, there was some in like Arizona and Iowa that there's been like repercussions within the environments there and the communities. Uh, what do you And and a lot of those companies don't have to report those things because it's considered proprietary, you know. Um, what do you think about those fears? Or how do you guys manage that? Like do you guys talk about that? Do you meet with environmentalists? Like what does that all look like?

[01:03:16] Sam Altman: I think we need to get to fusion as fast as possible.

[01:03:19] Theo Von: Get to what?

[01:03:20] Sam Altman: Nuclear fusion.

[01:03:21] Theo Von: Uh, I think that is the-

[01:03:23] Theo Von: Oh, shit. What is it?

[01:03:24] Sam Altman: Where you basically knock two small atoms together and it makes a bunch of energy, but no carbon, very clean, doesn't generate, you know, doesn't really harm the environment and power can become like abundant and pretty limitless on Earth. And we get out of all the current problems we're in.

[01:03:40] Theo Von: are you guys investing in that?

[01:03:41] Sam Altman: We are and I think AI can help us figure it out even faster. So that's like a, you know, if you have to like burn a little bit more gas in the short term, but you figure out, you know, the future of energy with that AI, it's a huge win.

[01:03:52] Theo Von: And would you guys sell tickets to that or what do you think that would be like?

[01:03:55] Sam Altman: Yeah, I think if people can watch that.

[01:03:57] Theo Von: Shit, I mean, yeah, people go to monster truck. You don't think they'll show up to watch those two things hit each other?

[01:04:02] Sam Altman: The atoms hit each other? It's pretty hard to watch two atoms hit each other, but maybe with the, you know, somehow we can do it.

[01:04:08] Theo Von: Or what if they did like those sperm races where they put them under those big things or whatever?

[01:04:11] Sam Altman: I love the sperm races.

[01:04:13] Theo Von: I mean that's kind of crazy.

[01:04:13] Sam Altman: I

[01:04:14] Theo Von: I'm like dude, there's enough of that going on.

[01:04:16] Sam Altman: Look, I think the- [laughs] Uh yeah, there'll be some way to watch fusion and it'll be awesome and it'll be like loud and bright and theatrical and it'll be making huge amounts of energy. Um even if you can't watch the two atoms hit, you'll watch them collectively produce a fireworks.

[01:04:33] Theo Von: But we're gonna need that, you think if we're gonna get to

[01:04:35] Sam Altman: I think so.

[01:04:35] Theo Von: if we're gonna get to uh, AGI or or if we're gonna get to uh super intelligence, do we need that?

[01:04:40] Sam Altman: I bet we can get there without it, but to provide it at the scale that humanity will demand it, I think we do need it. Because people the the the desire to use this stuff, people are just gonna want more and more and more. And eventually, like the the two things that I think matter most, the two kind of critical inputs are intelligence and energy. The ability to like have great ideas, come up with plans, and then energy is the ability to like make them happen in the world and also to run the intelligence. And I think the story of the next couple of decades is going to be the demand for these goes up and up and up to crazy heights and we better find out how to produce a lot. Otherwise, someone's going to feel like they're getting screwed.

[01:05:19] Theo Von: Yeah.

[01:05:21] Theo Von: Dang, dude. I can't tell if I'm excited or scared. Maybe I'm both. And maybe that's all the same thing.

[01:05:26] Sam Altman: You have to be both. You have to be both. I don't know if it's the same thing or not. I think it is kind of like, they do feel related to me always. Um, but I don't think anyone could honestly look at the trajectory humanity is on and not feel both excited and scared.

[01:05:42] Theo Von: Yeah. Hm. And maybe that's always been the way throughout time.

[01:05:46] Theo Von: And also then this is where we are. What are we getting what are you gonna do? You know, like this is where we are. And so that's what's going on.

[01:05:55] Theo Von: Um, I I saw where you and Joe Rogan spoke about there possibly being one day like an AI president, you know, where like could we have this one kind of like, let's just use the term supercomputer or this agent that was created that knew all the information and knew all the problems and knew the best ways to solve them. Um, is that, do you think that something like that is becoming more and more possible one day?

[01:06:20] Sam Altman: I don't know everything that it takes to be a president, but I do know it like it takes a lot of things that I don't have to do and that that people are going to well, maybe I could reframe it to an AI CEO of Open AI because I do know what that job is like. That should be possible someday, maybe not even that far. Like I think the idea to look at an organization to make really good decisions. There's a lot of things you can imagine that an AI CEO of Open AI could do that I can't. I can't talk to every person at Open AI every day. I can't talk to every user of chat GPT every day. I cannot synthesize all that information even if I could. But an AI CEO could do that and it would have better information, more context, it could, you know, massively parallelize this. And I think that would lead to better decisions in many cases.

[01:07:03] Theo Von: Yeah, because wouldn't a super computer or something that has all knowledge, which you think we'll get there?

[01:07:08] Sam Altman: I do.

[01:07:09] Theo Von: You do?

[01:07:10] Sam Altman: Well, I mean, all knowledge is a hard thing to say, but I think we'll have vast, vast amounts.

[01:07:15] Theo Von: Will it be able to tell us about God or anything, do you think?

[01:07:19] Sam Altman: I'm super curious about that. Uh, I think it will be able to help us answer questions about the nature of the universe that we currently can't. And I feel very confused and very unsatisfied with our current answers and there is clearly to me at least, something going on well beyond our current capability to understand. And I would love to know what that is.

[01:07:41] Theo Von: You think it could help us learn more?

[01:07:44] Sam Altman: Yes.

[01:07:46] Theo Von: What it does I wonder if God has a chat GPT or whatever or just wonder God he has the first one or whatever. But yeah, I'm just so curious like how would that work?

[01:08:00] Theo Von: Um, how does how does OpenAI make money?

[01:08:02] Sam Altman: We sell chat GPT. People pay 20 bucks a month. Some people pay 200, but very few or relatively few.

[01:08:07] Theo Von: Perverts, I think they are.

[01:08:09] Sam Altman: Uh, mostly hopefully they're just working super hard and using it for to be more productive with their job.

[01:08:14] Theo Von: Yeah.

[01:08:14] Sam Altman: And then we also sell an API. So businesses can use and they like pay us every time they make an API call.

[01:08:20] Theo Von: Okay. Um, do you think uh like there's a lot of these like kind of tech lords that are rocking right now, right? And you get thrown in there, you know.

[01:08:30] Sam Altman: Sometimes. I'm like on the periphery.

[01:08:32] Theo Von: Yeah, or you get certainly like, yeah, like these counsel, these councilmen kind of like. Do you think there's bad artists um amongst like these tech lords in these in these AI realms? Do you think there's bad artists out there?

[01:08:43] Sam Altman: What does bad artists mean in this context?

[01:08:44] Theo Von: Just like people that want for evil and not for good.

[01:08:48] Sam Altman: I think most people don't wake up I think very few people wake up every morning saying, I'm going to try to make the world a worse place or I'm gonna actively try to do evil. Clearly some do, but I think most of these people running the big tech efforts are not in that category. I think people get blinded by ambition. I think people get blinded by competition. I think people get caught up like very well-meaning people can get caught up in very negative incentives, negative for society as a whole. Um, and by the way, I include I include us in this. Like we can totally get caught up in we can be very well meaning but get caught up in some incentive and it can lead to a bad outcome. Um so that's kind of what I would say. I think people come in with good intentions, they clearly sometimes do bad stuff.

[01:09:37] Theo Von: There's a lot of talk about like Palantir and Peter Thiel and their company about being like a um, you know, they got a deal with from Trump about to have this surveillance or not a surveillance state, but to create a database on most of uh America. But it starts to feel like a surveillance state, you know? Um, do you feel like we will need something like that in order for uh the future? You know, do you feel like something like that is included in the future?

[01:10:08] Sam Altman: So I don't know about that specifically. I I mean I think Palantir and Peter do a lot of great stuff. Uh, but I I don't know, I can't comment on this specifically. I I'll say generally, I am worried that the more AI in the world we have, the more surveillance the world is going to want. Because the tool is so powerful that the government will say like, how do we know people aren't using it to make bombs or bioweapons or whatever? And the answer will be more surveillance. And I'm very afraid of that. So I don't, I think we really have to defend rights to privacy. I don't think those are absolute. I'm like totally willing to compromise some privacy for collective safety, but history is that the government takes that way too far. And I'm really nervous about that.

[01:10:54] Theo Von: Do you guys feel like the new government kind of? Or do you feel like the government is still like a real thing?

[01:10:59] Sam Altman: I don't feel like the government in any way.

[01:11:02] Sam Altman: When the US government bombed Iran recently, I remember waking up that morning and seeing that news or whatever time it was. Uh, and I was like, oh, that's what actual power looks like. You know, that we're in like a, maybe someday we get there. But it was like a really stark reminder of however important we think this is. It's like there are people that have just like this unimaginable power and might and can kind of do whatever they want. And that's definitely not us.

[01:11:32] Theo Von: Yeah. Yeah. I think that's been a lot in the Middle East recently, just like, it's just such a gross displays over there sometimes of inhumanity.

[01:11:41] Sam Altman: Absolutely.

[01:11:42] Theo Von: Sad. Um,

[01:11:43] Theo Von: what do you think a guy like then like Palantir and Peter Thiel's end game is? Do you think he has an end game? Because I think he seems like a dark lord to a lot of us and it's like he, do you think he has an end game that is like happy?

[01:11:55] Sam Altman: I think Peter is one of the most brilliant people I've ever met.

[01:11:59] Theo Von: Wow, he's smarter than me, that's for sure.

[01:12:01] Sam Altman: I think he does get characterized in the media as this like evil mastermind.

[01:12:07] Theo Von: As a villain he does.

[01:12:07] Sam Altman: I've never met him.

[01:12:09] Sam Altman: I've met him, we're we're very close friends. Uh, I

[01:12:12] Theo Von: Oh, I shouldn't have brought it up then.

[01:12:13] Sam Altman: No, it's all good. No, no, no. No, it's all good. I I don't feel that energy from him. But I, at all. Like I I in fact, I think he's been one of the most important forces at least in my life for questioning assumptions about the path that society was on and maybe I was like, oh, I thought this was all going well, but maybe we are in a text stagnation and maybe we really do have this huge economic challenge that no one's talking about. And, and so I think these people who are just very that think very differently, he would call it very contrarian, is is super important to a society. Now, on the other hand, um, [clip of Peter Thiel is shown] maybe he sometimes does things like this that don't do him any favors.

[01:13:08] Ross Douthat: You would prefer the human race to endure, right?

[01:13:12] Peter Thiel: Uh

[01:13:13] Ross Douthat: Youre hesitating.

[01:13:14] Peter Thiel: Yes? Well, I I don't know. I would This is a long hesitation. There's so many questions implicit in this. Should the human race survive?

[01:13:28] Peter Thiel: Uh, yes. But, but

[01:13:32] Theo Von: That was 22 seconds it took him.

[01:13:34] Theo Von: Oh my God. Jesus Christ, dude.

[01:13:36] Sam Altman: If he were if he were maybe like a more typical person, he would have just said an immediate yes and then said what else he wanted to say.

[01:13:42] Theo Von: Right.

[01:13:42] Sam Altman: But it took me a while with him to understand that his brain just works differently. And society needs some of that. Like he has these super different takes and then he doesn't have maybe the circuit in his brain that makes him immediately say yes and then say what he was going to say. But

[01:13:59] Theo Von: Maybe his processor is...

[01:14:00] Sam Altman: I'm very grateful he exists because he thinks of things no one else does.

[01:14:03] Theo Von: Yeah, I think, you know, yeah, you have to, you want, there novel thinkers have changed things throughout time. Sometimes for the better and sometimes for the worse, sometimes for the indifferent, but novel thinkers have, you've always like, I don't know, it's always been part of humanity.

[01:14:21] Sam Altman: I'm probably super different and super weird relative to most people, but, you know, maybe I have some ideas as part of that that are like valuable to society collectively. And if I had the sort of very standard mindset, I wouldn't.

[01:14:32] Theo Von: That's a good point. Yeah. Well, do you think, and I'm just gonna ask you brutally honestly, do you think a lot of these guys have, I mean, you know, it's now like, you know, love on the spectrum is like a big show, right? People, you know, and those people are in love, shit, everybody, half the people I know are just, you know, they're crying in parking lots or whatever. Um, you know, there's spousal issues, whatever. But anyway, what I'm saying is, do you think that some of the creators now and some of the tech lords almost have some tech built into them, like almost a I don't want to say like an autism, dude because that's...

[01:15:07] Sam Altman: You can say that.

[01:15:07] Theo Von: Okay.

[01:15:08] Sam Altman: I think so. I mean, yeah. I I, you know, to take the kind of like harshest look at us collectively, I can, you know, are we a little autistic on the whole? I I would say probably, you know.

[01:15:19] Theo Von: Fucking dude I knew that shit.

[01:15:19] Sam Altman: That's all right.

[01:15:20] Theo Von: No, no, I'm saying for years ago, I was meeting first time I ever met some people with autism, I was like, dude, these guys are computers, right? Like a lot of these guys are just, you know, they're some they're kind of like a little bit of a cyborg in some way in the way that they think, right?

[01:15:35] Sam Altman: You know, look, I'm you are this like impossibly charming and cool guy and I'm like kind of a lot more computer-y than you.

[01:15:40] Theo Von: Not much though.

[01:15:41] Sam Altman: But we can have a, we can still like figure it out.

[01:15:44] Theo Von: Oh yeah. I and I I really don't mean it's an offense, but I think we may need that in people to get whatever's next in the world.

[01:15:51] Theo Von: Do you think that's realistic?

[01:15:52] Sam Altman: Yeah, I think society needs like this very broad diversity of people. You need some people like me, you need some people who are more normal than me. You don't want too many of me, but you know.

[01:16:02] Theo Von: Yeah. Yeah, you want too many of anyone, thank you. But yeah.

[01:16:05] Theo Von: Yeah, I'm just always I'm like, God, yeah, these people are able to see things differently and quantify things differently. Do you always feel, because some tech guys, they just have a different understanding of possibility, right? A different understanding of feeling and thing. Do you feel human all the time?

[01:16:22] Sam Altman: I do feel human all the time, but I do feel like I I have noticed that I think extremely differently about the future, about exponential change, about compounding technology, than almost anybody else that I kind of come across in regular life. So I feel extremely human. I feel like, you know, driven by crazy emotions as much as anybody, but I am like very aware that I have a different lens than a lot of people.

[01:16:47] Theo Von: Have you met some people in tech space you're like, whoa, that guy's only like six or seven percent, he has low, not a lot of human in him.

[01:16:53] Sam Altman: Yes.

[01:16:54] Theo Von: Yeah.

[01:16:55] Theo Von: Yeah. Okay. I

[01:16:59] Theo Von: Um, do you think it's inevitable that AI or AGI will merge into our bodies? I know you've talked about this before in the past.

[01:17:07] Theo Von: As things go along and advance quickly, do you start to see that a little bit differently? I know you've talked about how you don't think it's like a glasses thing or something like that.

[01:17:13] Sam Altman: I'll tell you a fascinating story. Okay. I was with a friend last week.

[01:17:17] Theo Von: And did I offend you by asking that?

[01:17:18] Sam Altman: Not at all.

[01:17:18] Theo Von: Okay, sorry.

[01:17:19] Sam Altman: Zero percent.

[01:17:19] Theo Von: I thought that was a great answer and I really appreciate it. Because yeah, some of us are we can't conceptualize sometimes how you guys are thinking. It can't I can't even like we feel like we can't figure it out, you know. So it feels like it's almost like a unique it's like are we all evolving into this new kind of species and that's where we meet the future at anyway and you're just like the dang Paul Revere out, you know, it's like

[01:17:41] Sam Altman: I think whenever you see someone who thinks differently than you, it's like like I'm fascinated by you. I don't quite understand how you do your thing. I know I couldn't do it. I know you like just understand the world differently than me. But I think that's cool. And I'm just like, all right,

[01:17:55] Theo Von: I'm glad we're different. Yeah, that's how I feel. I think it's just thanks for just talking with me about it.

[01:17:59] Sam Altman: Of course.

[01:17:59] Theo Von: Thanks for your time today.

[01:18:00] Sam Altman: I appreciate it, man. I don't think I don't think you should be offended. I don't think anybody'd be offended by that. Um, I was talking to this friend of mine though about how he uses chat GPT and he's been using it a lot for a couple of years now. And he noticed recently that he started he started giving it personality tests. He'd upload any personality test he could find to chat GPT and say, based on what you know about me, answer this. And he had never, he had never like told it here's my personality. He had just learned it from the questions he asked over the years. And on everyone he tried, it got the exact the answer and the exact in the outcome he would get. And so that's not like he didn't get uploaded, he didn't get merged, he didn't plug something into his brain. But somehow like the pattern of him had gotten imprinted into this AI.

[01:18:46] Theo Von: Wow. Maybe we're not as complex as we think we are.

[01:18:50] Sam Altman: Or maybe we are and AI can just learn it really well. AI can like represent these very complex things. One of those two. But that was a real moment for me of like, wow, you know, the merge may be can happen in a very different way than we thought.

[01:19:04] Theo Von: Yeah. Yeah, because you think of it as this thing kind of taking over your system and like, you know, your dad presses a button and you can't use the car, you know, you can't move for a month or whatever. Yeah, I think it it kind of has that sort of energy.

[01:19:17] Theo Von: Um, you just, you just finished the acquisition of this a little bit more like day-to-day business. You just finished the acquisition of Johnny Ive's, um, hardware company. Um, their hardware company. So clearly you have some like thoughts or interests in how like hardware and AI match up for each other in humanity. What was that about?

[01:19:43] Sam Altman: There have been two revolutions in computers in history. There was the keyboard, mouse and screen, that thing that was invented down the street in I think the 70s where, you know, the people at Xerox Park figured out what has become the modern computer interface. And then in the early to mid the early 2000s, I guess, Apple figured out this idea of touch on a device. And really, those have been the two big ones. I think now there can be a third. I think AI is it's so changes the game that you can design a new kind of computer based off of a really smart AI where you can give a complex instruction to a system, it can go do it, you'll trust it, it gets it right. You'll trust it to act on your behalf. It could like maybe be aware of everything going on in this room and it could like not just be on or off, but like lightly get our attention if it wants us to know something or more aggressively get our attention. It could really be like following what we're talking about here and remind us both of things later. Um, and current hardware just can't do that. The current kind of computers we have, I don't think are a fair they don't honor what the technology is now really capable of. So, I want to make a totally new kind of computer that is meant for this world of AI helping you all the time.

[01:20:55] Sam Altman: I'm super excited about it.

[01:20:56] Theo Von: You are?

[01:20:56] Sam Altman: Yep.

[01:20:57] Theo Von: Um, you guys, there's a thing called Agent that you guys just showed me earlier. I can take this out if I mentioned it, I wasn't supposed to.

[01:21:05] Sam Altman: No, you can.

[01:21:06] Theo Von: It was pretty fascinating.

[01:21:07] Sam Altman: It was cool to see.

[01:21:08] Sam Altman: It it is, yeah. This this is a new thing that we just did. Um, but the idea that an AI cannot just answer questions for you, but it can go and actually do stuff on your behalf as your agent. It can go do research for you, it can go book something for you, it can go buy something for you, it can go like, you know, change some things in the world for you and think more and use tools like, I think most people think of ChatBT as this app that you can ask anything. But it'll become this thing that can do anything. And that'll change how you use computers. It'll change how you do things in your life. You know, if you-

[01:21:42] Theo Von: Yeah. I was watching the guy do it and it was just kind of fascinating. He was showing like one time he had went to like a website and bought something that he needed and then now moving forward he could just be like, hey, go to this and make sure to get me these or go to uh go here and see if there's any table available for 7:00 p.m. tomorrow. And it was able to book it and do everything. It was like having a secretary right there.

[01:22:03] Sam Altman: It totally. When I first started using it, I was like, it was one of those moments where I could tell that, oh man, doing this the old-fashioned way is gonna feel like the Stone Age so quickly. You know, I'm gonna like try to tell people someday like, do you remember when if we wanted to do something, we actually had to go like click around the internet and like, you know, look for a table. And then if we wanted to move it, we had to like call the restaurant. And that's gonna be unimaginable because of course you just tell your AI to do those things for you.

[01:22:31] Theo Von: Yeah. Yeah, you'd feel like you'd almost just tell it to go eat too, you know.

[01:22:35] Sam Altman: That's the fun part.

[01:22:35] Theo Von: Yeah, that's right. That's the fun part. No one likes booking the table. Everyone loves sitting there eating.

[01:22:39] Theo Von: That's a good point, huh? Yeah, yeah, it won't take away the fun part. That's the thing. I think you got to remember that it won't take away the fun part.

[01:22:45] Sam Altman: You're going to do the things you want to do. There's a lot of things in your life you probably don't love doing. Like booking an open table is maybe one of them.

[01:22:51] Theo Von: Yeah. And then you'll have like old-fashioned be like, I'll book it, you know, you're like, Dad, what are you mean? Get off the phone or whatever. Don't call him, you freaking weirdo. Use a freaking, use your agent.

[01:22:59] Sam Altman: Totally.

[01:23:00] Theo Von: I'll book it.

[01:23:02] Theo Von: Um, there's there's a lot of like, you know, Zuckerberg recently like kind of was poaching guys around town, right? And I'll say it, you don't have to say it, allegedly. I'm not saying he did. He hired one of my buddies. But what I'm saying is, um, there's this hypothetical that he was like kind of poaching guys around town. Is that did it that feel like a Mafioso move in the community? What was that like out here on the out here in the uh tech trenches.

[01:23:27] Sam Altman: I mean, you know, they want to get into the AI game. I understand it. And if he's going to do this,

[01:23:36] Theo Von: fucking brilliant, he needs to hire some people.

[01:23:37] Sam Altman: So bring it. So bring it.

[01:23:39] Theo Von: Yeah. So bring it. Fucking yeah, dude. I'm gonna upload myself into this plant in a second. Um, okay, no, but no, does it do you kind of like the competition? Is that fun?

[01:23:50] Sam Altman: It is it's yeah, winning is fun. And I expect to win.

[01:23:53] Theo Von: And you got to love the competition. That's part of it, right? It makes it fun.

[01:23:57] Sam Altman: I think what it would be like if we didn't have competition and drama in the world, it would be so boring.

[01:24:05] Theo Von: Could, uh

[01:24:06] Sam Altman: actually, can I say one more thing about that?

[01:24:07] Theo Von: Yeah, sure.

[01:24:08] Sam Altman: The best improvement I made in my life in my like personally and in my life and for my own happiness over the last couple of years. A lot of bad shit has happened to us, to me. It's been like a crazy intense experience. And I just decided that I was going to like learn to love the hard parts. I was like, you know what? If I'm in this crazy moment, if I'm in this like crazy thing, if I like feel my emotions are high, I'm going to like make myself learn to be grateful for that, to love it, to find enjoyment in the in the tension and the competition and whatever. And actually it worked. And it it kind of needed to work because like so many things go wrong in any given day. But I was like thinking about, you know, someday I'll be like retired on my ranch. I'll be sitting there watching the plants grow and I'll be missing the excitement and the drama and the anger and the tension and the whatever. And so I'm going to be like grateful for it and like learn to have fun with it now. And now, it I can't I cannot believe that that mindset mindset shift worked, but it did.

[01:25:02] Theo Von: And were there practices like in a moment, like say like a moment came up like some of the early ones, right? Cuz I agree with you that like having some mindset, like I used to hate traveling every week traveling for work. But then one day I was like, dude, you have to travel for work. Deal with it.

[01:25:16] Sam Altman: You may as well. Find a way to-

[01:25:17] Theo Von: You may as well. Because for years you've been just and right there, suddenly it wasn't bad anymore.

[01:25:21] Sam Altman: That happened for me too.

[01:25:23] Theo Von: Was there like a just a practice or was it just this verbal reminder like I'm gonna do this?

[01:25:27] Sam Altman: I just kept saying it to myself.

[01:25:28] Theo Von: Yeah.

[01:25:28] Sam Altman: I was just like, someday you'll miss these moments. You may as well find a way to like find the happiness and kind of like great gratitude for them in the moment.

[01:25:38] Theo Von: Yeah.

[01:25:39] Theo Von: Um, a lot of these guys have bunkers. Zucky has a bunkie, I know that somewhere out in Hawaii. People have bunkers. Do you have a bunker?

[01:25:49] Sam Altman: I have like underground concrete heavy reinforced basements, but I don't have anything I would call a bunker.

[01:25:56] Theo Von: Hold on, hold on, hold on, dude. Look, I'll let you I'll let you keep me on the ropes in a lot of this conversation, but I'm going to call that out as a dang bunker, dude. Sam, that's a bunker.

[01:26:05] Sam Altman: What's the difference between a basement and a bunker?

[01:26:07] Theo Von: A one, a place you could hide when it all goes off or whatever.

[01:26:10] Sam Altman: Yeah, no, yeah, I have been thinking I should really do a good version of one of those. But I don't I don't have what I would call a bunker, but it has been on my mind. Not because of AI, but just because of like people are dropping bombs in the world again and, you know, like

[01:26:25] Theo Von: that's a good point. It's a very good point. Yeah, Basement, right there, part of a house/building typically used for storage, laundry, extra living space or utilities. And then bunker built for protection, often military or emergency related meant to withstand explosions, radiation, or natural disasters.

[01:26:40] Sam Altman: Yeah, we don't have that yet. Do you guys do this just for me or do you use chat GPT as the fact check?

[01:26:44] Theo Von: We did this just for you.

[01:26:45] Sam Altman: I appreciate it.

[01:26:46] Sam Altman: This is nice.

[01:26:47] Theo Von: Um, if could we ever could we ever have instead of say if AI comes over and there's this whole new kind of like, you know, I believe that one of the things that's been happening, there's been like a lot of like ice raids and people getting like taken out of their homes and um, uh, you know, um, there's been a lot of crackdowns cuz part of me believes that they're having to get everybody documented or online basically because they're going to start to have this like this like uh this like surveillance layer that's kind of in the in the air then could that be divided into different realms?

[01:27:23] Sam Altman: Oh, yes, totally. I think there's all kinds of weird ways that that can happen. But but the surveillance layer is so uncomfortable.

[01:27:31] Theo Von: Oh, yeah. It's going to be a nasty blanket. Um, is there anything else that you wanted to talk about you wanted to get out that you wanted me to ask you about?

[01:27:38] Sam Altman: No, that was great.

[01:27:40] Theo Von: Okay. Oh, why are there why does ChatBT have that hyphen thing?

[01:27:45] Sam Altman: We we got to do something about that. Um, you know, we have this team that figures out what the model's personality should be like and how it should behave. And a lot of users like M dashes. So we added more M dashes and now I think we have too many M dashes. And it's kind of it's quite annoying to me. We should we should fix that.

[01:28:08] Theo Von: But you're thinking about it, too?

[01:28:09] Sam Altman: I think we'll get it fixed very soon.

[01:28:11] Theo Von: Okay. Um, before you go, Sam, and thank you so much for your time today.

[01:28:14] Sam Altman: It's been awesome.

[01:28:15] Theo Von: We appreciate it, man.

[01:28:15] Sam Altman: Thanks for thanks for doing this. I really enjoyed it.

[01:28:16] Theo Von: Thanks for your time today. I thought it was very informative. It helped me get to understand you I feel like a lot. I think maybe differently than I I don't I don't know if I had a perception. I didn't know what to think.

[01:28:23] Sam Altman: What's the before and after?

[01:28:25] Theo Von: Uh, the before was like a little bit like um I guess I almost thought kind of like not as hopeful. But I don't know why maybe that's just my own I think it's attached to my own perceptions of what I think about AI and stuff or the possibilities of technology, you know, like that kind of stuff. Like that curmudgenny energy, I think I was probably attaching it to you and now I feel like I can a more whimsical about it kind of like, or not whimsical but like, let's see what can happen.

[01:28:57] Theo Von: Right?

[01:28:58] Theo Von: And so I think

[01:28:59] Sam Altman: I think it's not just let's see, it's like let's try to make it good, but let's realize that you have to like, you don't get to see all the way down the road. You kind of got to go one turn at a time and you like light up a little bit more.

[01:29:08] Theo Von: Yeah. Yeah, I think, yeah, I don't know. I'm just I'm really thankful for you even let me tell you what I thought what what what I was thinking and then, uh, and then sharing like what what I thought now. Um, in 20 years, what do you hope your legacy will be?

[01:29:11] Theo Von: You're gonna have one.

[01:29:12] Sam Altman: I mean, yeah, I guess. I I don't think anyone sits around while they're in like the middle of the game thinking about, you know, what the review is going to be after. At least I don't. And

[01:29:15] Sam Altman: Your brain sorry?

[01:29:16] Theo Von: with the people over there. Cryonics.

[01:29:18] Theo Von: Do you have a Cryonics deal?

[01:29:19] Sam Altman: No, I uh,

[01:29:22] Sam Altman: I have never been that motivated by like what like I want to like play the game the best I can. I want to like, you know, do the best work I can, have the most fun, have like, you know, have the most impact or the most interesting stuff. But then, you know, you retire and then you die and then people as they're supposed to go on with life and forget about you. And this whole thing of like, I'm going to live for how I'm remembered after I die and my legacy and like, you're dead, you know.

[01:29:22] Theo Von: Have you been approached about it?

[01:29:23] Sam Altman: I have been approached by it. There was like a-

[01:29:24] Theo Von: crazy. They haven't even fucking approached me yet. They ask for anything.

[01:29:27] Sam Altman: There was this like why Combinator company that I helped out a long time ago by like giving some small deposit and then I never followed up on it. So I don't have anything in place.

[01:29:37] Theo Von: But maybe I just a down payment somewhere down there. At things get weird, we'll we'll go knocking on their door.

[01:29:38] Theo Von: But this is a big review you'll have.

[01:29:40] Theo Von: I mean, that's not...

[01:29:41] Theo Von: I

[01:29:42] Sam Altman: I

[01:29:42] Theo Von: Do you have one of those deals where you save in your heart with those people?

[01:29:43] Theo Von: Uh but thank you so much man. James Bashara says hello. He's a friend of mine. He's a great guy. And uh and we just appreciate you so much, Sam. Thanks for your time.

[01:29:52] Theo Von: Of course.
